{"pages":[],"posts":[{"title":"Github + Hexo 搭建博客(一)","text":"1 申请Github的page域名访问Github官网新建账号，并创建个人仓库。 在个人仓库操作框下进行设置settings，要满足三级域名要求必须进行如下操作。 Repository name 必须保证三级域名与账号一致，且以io顶级域名结束，否则访问路径会出现在路径分隔符后。例如：正常域名:alpacaca.github.io；错误域名www.github.com/alpacaca/xxxblog 如果正确创建，在GitHub Pages中正确显示已经发布的域名地址 可以在个人repo的master分支中创建readme.md用作说明或提示类信息（不要求）。 下载Github工具，安装带有Github Bash的命令提示符。 2 配置环境并下载HexoHexo下载安装依赖npm，npm是nodejs包管理器，nodejs安装依赖python环境 下载python3版本并安装，在环境变量path中添加python解释器的路径。添加项应是安装路径下的python3.exe 下载stable稳定版nodejs并安装，需要安装npm包管理器。使用以下命令查看npm 和node的版本是否正确。 12user &gt; npm -vuser &gt; node -v （由于万里长城的原因，npm默认中央仓库可能无法正常访问或者加载速度过慢）这时，需要通过以下命令查看metrics-registry参数 1user &gt; npm config list taobao提供国内npm仓库镜像https://registry.npm.taobao.org/，可以通过以下命令设置。1user &gt; npm config set registry http://registry.npm.taobao.org/ 此时，nodejs和npm的准备工作已经完成。 通过npm安装hexo12345#(此处为注释，下同)全局安装hexo组件user &gt; npm install hexo -g #安装完毕查看hexo版本user &gt; hexo -v 可以通过cmd进入硬盘任意位置 或者 在任意位置通过地址栏输入cmd打开命令提示符，初始化hexo组件、安装并初次运行12345678910111213# 初始化hexo组件d:\\blog &gt; hexo init# 安装依赖组件d:\\blog &gt; npm install# 当全部完成后，生成静态文件d:\\blog &gt; hexo g# 本地浏览d:\\blog &gt; hexo s -o# hexo默认端口4000，如果此处端口被占用，可以使用下列命令，xxx为自定义端口d:\\blog &gt; hexo s -o -p xxx 至此，当在浏览器中出现下图，表示hexo已经在本地可以完美运行。接下来需要发布blog到Github，并在互联网上进行访问。 结尾本地初始化博客已经跑起来了，如何部署到远端通过互联网域名方式访问，将在下节展开","link":"/2018/09/19/1 Github + Hexo 搭建博客/1 Github + Hexo 搭建博客(一)/"},{"title":"Github + Hexo 搭建博客(二)","text":"3 创建Github SSH连接Github支持https和ssh两种方式管理本地和远程代码的同步，作为个人repo的拥有者，推荐使用ssh方式，因为每次写博客上传远端库时可以省略用户名和密码的验证。 ① 创建ssh key 1$ ssh-keygen -t rsa -C &quot;your_email@example.com&quot; “your_email@example.com“使用github个人账户邮箱，创建成功后连续三次回车，以下分别说明 12Generating public/private rsa key pair.# Enter file in which to save the key (/c/Users/you/.ssh/id_rsa): [Press enter] 第一次要求输入保存公钥和秘钥的文件路径，直接回车视为默认，保存在/c/Users/you/.ssh/id_rsa下 12Enter passphrase (empty for no passphrase): # Enter same passphrase again: 接下来两年次回车是提交密码和密码确认，可以默认无密码。 当然，如果要设置密码需要说明，该密码仅为push本地代码到远端时的密码，而非账户密码，建议省略。 接下来，就会完成创建并保存到本地 1234Your identification has been saved in /c/Users/you/.ssh/id_rsa.# Your public key has been saved in /c/Users/you/.ssh/id_rsa.pub.# The key fingerprint is:# 01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db your_email@example.com ② 绑定ssh key 在保存路径下找到id_rsa.pub，打开并复制其中的内容 登录github，在个人Setting下找到SSH and GPG keys 并将复制的内容添加一个新的SSH Key。 至此，绑定ssh完毕 ③ 测试ssh连接在git bash中输入以下命令 12345$ ssh -T git@github.comThe authenticity of host &apos;github.com (207.97.227.239)&apos; can&apos;t be established.# RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.# Are you sure you want to continue connecting (yes/no)? 显示警告无妨，输入yes并继续，会得到最终测试的结果。 12Hi username! You&apos;ve successfully authenticated, but GitHub does not# provide shell access. 如果显示successfully authenticated表示ssh授权成功，可以使用； 相反，如果提示access denied表示失败，可以删除已绑定的ssh并重新进行②步骤，注意粘贴内容不含其它字符包括空格和回车。 4 将初始化博客部署至github上一节最终已经在本地初始化了hexo博客并且正常运行，接下来需要部署至github的仓库并通过互联网域名进行访问 ① 首先，需要在根路径安装自动部署插件 1d:\\blog &gt; npm install hexo-deployer-git --save ② 配置部署信息 首先，访问github，并在上节创建的仓库中找到专属SSH连接地址，复制该地址 其次，在本地根路径下打开_config.yml文件，找到deploy对象并进行配置 说明1：由于建议使用ssh方式，这里type和repo都是ssh连接。当然也支持https方式，在②中就需要复制https对应得到地址配置在此处 说明2：github搭载的hexo只支持上传master分支，如果上传其他自定义分支是无法正常显示的。所以branch配置master分支 说明3: yml文件特别需要注意冒号后的一个空格，如果疏忽则会导致配置出错。并且yml文件受到缩进的严格限制来进行归类，这区别于properties文件和json文件。 ③ 自动化部 使用以下命令进行生成静态文件和部署操作。 1d:\\blog &gt; hexo d -g 或者 123d:\\blog &gt; hexo gd:\\blog &gt; hexo d 当显示部署成功后,就可以通过上节中配置的域名https:\\\\yourdomain.github.io进行访问，当然，你也可以访问github仓库查看本次上传的全部内容。 结尾 OK，你期望的美好正在发生，但是觉得页面太丑？或者我如何发布自己写的博客，这将在下节展开","link":"/2018/09/26/1 Github + Hexo 搭建博客/2 Github + Hexo 搭建博客(二)/"},{"title":"Github + Hexo 搭建博客(三)","text":"5 Hexo全局配置初次浏览全局配置文件，在本地根目录下找到_config.yml文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283# Hexo Configuration## Docs: https://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Sitetitle: zhy's blogsubtitle: Stay Hungry , Stay Foolishdescription:keywords: zhy blogauthor: zhylanguage: zh-Hanstimezone:# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://yoursite.comroot: /permalink: :year/:month/:day/:title/permalink_defaults:# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: truerelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: # Home page setting# path: Root path for your blogs index page. (default = '')# per_page: Posts displayed per page. (0 = disable pagination)# order_by: Posts order. (Order by date descending by default)index_generator: path: '' per_page: 10 order_by: -date # Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map:# Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: yilia# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:alpacaca/alpacaca.github.io.git branch: master 注意：yml文件相比于properties配置文件，更加简洁。类似于python代码，主从配属严格受到缩进的影响，特别特别需要强调的是，配置名后的冒号和参数之间是一定有空格的！ 接下来分别认识一下配置文件。 站点和url配置123456789101112131415# Sitetitle: zhy's blogsubtitle: Stay Hungry , Stay Foolishdescription:keywords: zhy blogauthor: zhylanguage: zh-Hanstimezone:# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://yoursite.comroot: /permalink: :year/:month/:day/:title/permalink_defaults title ， 是浏览器标签显示的名字 subtitle ， 子标题 keywords ， 主要用于SEO，可以采用列表表示[key1,key2],下同 author, 作者 language: 初次加载根据pc环境选择，可以手动修改 timezone： 时区，默认同系统 说明 如果你部署的博客地址并非三级以内的域名，而是地址分割符后的，比如http://github.com/alpacaca，那么需要配置url信息，如下 url： 默认不变，如果是地址分割符后地址需要配置http://yoursite.com/child root: /child/ permalink: 永久链接 目录123456789# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render: source_dir 资源文件夹，这个文件夹用来存放内容。 public_dir 公共文件夹，这个文件夹用于存放生成的站点文件。 tag_dir 标签文件夹 archive_dir 归档文件夹 category_dir 分类文件夹 code_dir Include code 文件夹 i18n_dir 国际化（i18n）文件夹 skip_render 跳过指定文件的渲染，可使用 glob 表达式来匹配路径。 写作123456789101112131415# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: truerelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: new_post_name 新文章的文件名称 default_layout 预设布局 auto_spacing 在中文和英文之间加入空格 titlecase 把标题转换为 external_link 在新标签中打开链接 filename_case 把文件名称转换为 (1) 小写或 (2) 大写 render_drafts 显示草稿 post_asset_folder 启动 Asset 文件夹 relative_link 把链接改为与根目录的相对位址 future 显示未来的文章 highlight 代码块的设置 分页、主题和部署12345678910111213141516# Pagination## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: yilia# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:alpacaca/alpacaca.github.io.git branch: master per_page 每页显示博客数 pagination_dir 分页目录 theme 主题，将在下节介绍 deploy 部署 关于deploy当安装了hexo部署插件后，可以通过配置deploy自动进行部署，我选择的是以git方式发布到repo中的master分支 最终，使用hexo d -g发布到远程仓库 6 主题的选择和配置如果不喜欢Hexo的默认主题（没有人会喜欢[doge]），官方还提供了大量的主题类型，可以访问这里选择自己认为ok的主题 比如：中意首页展示的Aria主题，那么你可以在最下方footer标签范围找到该主题对应托管在github上的资源clone该项目到本地根目录下的themes文件夹下。 首先，需要在根目录下的/_config.yml中配置theme指定aria 1234# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: aria 之后进入主题内的置/themes/aria/_config.yml文件中进行自定义配置 关于主题这里就不展开了，因为不同的主题都有各自不同的配置要求，具体说明可以在打开的github资源首页READEME.md下找到 当配置完之后可以本地查看修改后的状态，运行1d:\\blog &gt; hexo s -o 结尾经过定制化的个人博客成功运行，你可以动手写文章啦！什么？你还不知道怎么写？那么我们下一节介绍具体介绍。 目前博客的书写均采用MarkDown进行编辑，如果你已经掌握可以跳过下节","link":"/2018/09/30/1 Github + Hexo 搭建博客/3 Github + Hexo 搭建博客(三)/"},{"title":"Github + Hexo 搭建博客(四)","text":"7 Hexo写作和Markdown首先介绍Hexo博客的原理：本地编辑好的文本通过hexo generate命令，编译为静态html文本并发布到远端展示。换句话说，Hexo展示的内容都是Html文本形式的，这就意味着在本地编写的文本支持编译html。 这就引入了Markdown文本编辑 Markdown，是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式(无法访问wiki，摘自百度百科解释)。 对于Markdown写作的规范和优势，可以自行百度，这里不多做解释，只需要记住一点，Markdown可以让我们更加关注内容的编写而不用花费更多精力在格式排版上。 既然作为标记语言，那么同样支持W3C规范的html标签。 比如:一级标题、二级标题、三级标题等对应的Markdown格式为#一级标题、##二级标题、###三级标题也可以使用Html标签&lt;h1&gt;一级标题&lt;h1&gt;、&lt;h2&gt;二级标题&lt;h2&gt;、&lt;h3&gt;三级标题&lt;h3&gt; Markdown文本编辑工具由于我个人在此之前长期使用印象笔记记录内容，搭配使用的是(马克飞象)[https://maxiang.io]Markdown编辑工具，良好的支持本地活在线编辑并和印象同步内容，然而马克飞象并不是当做其他md文本编辑的好工具。 在使用了一众md编辑工具后，最终还是选择安利Visual Studio Code。VS Code本身并不是md工具，只是微软做出来与WebStorm抗衡的前端IDE，然而它实在是太优秀了，并且很好的支持Markdown的编辑工作，甚至hexo根目录下的yml文本、前端各种文本都可以编辑和展示，软件反应灵敏且安装容量极小，这就让我爱不释手。 注意：不同的md编辑工具可能某些语法并不相同，比如Latex公式、表格甚至链接和图片等。但总的md标记不变，只是在不同工具上渲染出的效果不一样.这就好比不同的浏览器，内核不同，渲染出的网页效果也有一定的出入。具体最终渲染出的效果什么样还要遵循Hexo的md规范。 写作新建写作Ok，假设你已经掌握了md的基本语法，我们接下来可以正式进入编写博客了。 1d:\\blog &gt; hexo new myblog 使用该命令创建一个新的文章，myblog会保存在_posts文件中，该文件是博客存放和最终编译静态标记文本的路径。当然你也可以使用如下命令创建本次草稿，并最终移动到_posts下发布到远端（个人不推荐，原因是麻烦且没必要）12345d:\\blog &gt; hexo new draft myblog #创建草稿myblog并在draft文件下保存# 编写草稿内容，完成后执行d:\\blog &gt; hexo publish [scaffold] #将草稿移动到_posts下，也可指定scaffold模板 写作模板说明1234567---title: Github + Hexo 搭建博客(四)date: 2018-9-30tags: hexotoc: hexo---# 内容 目前我采用的写作头文件是这样： title: 表示文章的标题，也是在博客首页最上方醒目显示的地方。 date： 文章写作时间 tags: 本所所属的标签，标签可以是单个标签，也可以是标签序列，如tags: [github, hexo, blog],需要在根目录的_config.yml中开启标签支持 toc： 文章目录。 申明头部之后，就可以在下方开始使用md书写内容了。 博客内图片Markdown内的图片常规引入方式为使用标记![text](imgurl)，然而在hexo中并不适用，这也是标记不一致的地方，由于Hexo要生成静态页面，需要在同级目录中创建保存静态文件的文件夹。具体方式如下：在根目录_config.yml中配置1post_asset_folder: true 在使用命令d:/blog &gt; hexo new myblog后会在同级目录中创建同名文件夹，将需要引入文章的图片保存在该文件夹中并命名，比如test.jpg。在md文本中使用如下命令引入1{% asset_img test.jpg Hexo %} 创建博客评论功能之——Gitment登录Gitment进行注册，注册成功后会获得client_id和client_secret,进入主题下的_congif.yml配置如下：12345gitment_owner: alpaca #你的 GitHub IDgitment_repo: &apos;https://alpacaca.github.io/&apos; #存储评论的 repogitment_oauth: client_id: &apos;xxx&apos; #client ID client_secret: &apos;xxx&apos; #client secret 配置成功后文章底部就会支持Gitment评论功能。 注意：Gitment目前只能登录git账号后才能评论切勿滥用！可以看这里 结尾Github + Hexo搭建博客，暂且告一段落。当然，有深度定制Hexo需求甚至自建风格都可以参照官方文档进行开发，或者可以通过修改主题内的ejs文件和css文件。","link":"/2018/10/02/1 Github + Hexo 搭建博客/4 Github + Hexo 搭建博客(四)/"},{"title":"MySQL优化系列（一）","text":"MySQL优化系列（一） 0 总述按照Java当前框架式的开发模式，我总结单系统Mysql优化主要分为三类： 代码级优化。 数据库级优化。 框架级优化。 代码级优化主要包含： 尽量使用联接查询代替子查询（嵌套查询）。 避免使用关键字LIKE或正则表达式匹配，会导致全表扫描。 DELETE删除大量数据后，使用Optimize table tb_xxx释放残余空间。 避免在where中使用函数或表达式。 避免使用使索引失效的操作。 避免使用select *，会导致全表查询。 使用相对较高的性能分页，比如where id &gt; 100 limit 20 性能优于limit 100, 20。 Join时使驱动表为小数据量表。 数据库级优化主要包含： 建立索引，并使用explain调试接近最优查询。 合理使用存储过程。 选择适合业务特点的数据库引擎（事务、锁机制）。 掌握使用慢查询日志。 mysql buffer和cache。 物理资源使用分析（cpu使用率和io阻塞）。 框架级优化主要指多级缓存策略，其中包含： 关系型数据库中，ORM框架支持的一二级缓存。 非关系型数据库中，redis数据库缓存。 1 准备1.1 数据准备&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在展开研究Mysql数据库优化前，我们先创建一组数据，用于分析所有涉及的操作行为。四张数据表的数据字典如下：（主键id均为整型自增，非特别说明都使用varchar类型） tb_course : id，name（课程名），is_required（是否必修课 boolean），credit（学分 int） tb_teacher : id，name（教师名），age（年龄），course_id（所授课程id） tb_student : id，name（学生名），age（年龄 int） tb_student_course : id，student_id（学生id），course_id（课程id），is_pass（是否及格 boolean），score（得分 int） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;创建数据库脚本代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788CREATE DATABASE `optdemo` CHARACTER SET 'utf8';USE `optdemo`;#创建课程表，包括id，名称，是否必修课，学分CREATE table `tb_course`( id int primary key auto_increment, name varchar(20), is_required boolean, credit int)ENGINE = InnoDB CHARACTER SET = utf8;#创建老师表，包括id，名称，年龄，教授课程CREATE table `tb_teacher`( id int primary key auto_increment, name varchar(20), age int, course_id int)ENGINE = InnoDB CHARACTER SET = utf8;#创建学生表，包括id，名称，年龄，所学课程CREATE table `tb_student`( id int primary key auto_increment, name varchar(20), age int)ENGINE = InnoDB CHARACTER SET = utf8;#创建学生--课程关系表，包括id，学生id，课程id，是否通过CREATE table `tb_student_course`( id int primary key auto_increment, student_id int not null, course_id int not null, is_pass boolean, score int)ENGINE = InnoDB CHARACTER SET = utf8;#初始化表INSERT INTO `tb_course` (name, is_required, credit) VALUES ('C', true, 4), ('JAVA', true, 4), ('数据结构', true, 3), ('操作系统', true, 4), ('C#', false, 2), ('Python', false, 3), ('人工智能', true, 4), ('TCP/IP', false, 2), ('计算机网络', true, 3),('Linux', false, 2);INSERT INTO `tb_teacher` (name, age, course_id)VALUES('老张', 45, 1),('老王', 46, 2),('老李', 48, 3),('老赵', 35, 4),('老吴', 55, 5),('老孙', 45, 6),('老刘', 40, 7),('老贾', 39, 8),('老钱', 32, 9),('老周', 36, 10);INSERT INTO `tb_student` (name, age)VALUES('小张', 18),('小王', 18),('小李', 18),('小赵', 18),('小吴', 18),('小孙', 18),('小刘', 18),('小贾', 18),('小钱', 18),('小周', 18);INSERT INTO `tb_student_course` (student_id, course_id, is_pass, score)VALUES(1,1,true, 80), (1,2,true, 90), (1,3,true, 92), (1,4,true, 93), (1,7,true,87), (1,9,true, 89), (1,10,true, 78), (2,1,true, 99), (2,2,true, 98), (2,3,true, 100), (2,4,true,100), (2,7,true,95), (2,8,true,91), (2,9,false,55),(3,1,true, 76), (3,2,true,68), (3,3,true,82), (3,5,true,77), (3,7,true,71), (3,9,false,59),(4,1,true,100), (4,2,true,100), (4,3,true,100), (4,4,true,100), (4,7,true,100), (4,9,true,100),(5,1,false, 42), (5,2,false,39), (5,3,false,33), (5,4,false,21), (5,5,true,60), (5,7,false,0), (5,9,false,58),(6,1,false,82), (6,2,true,78), (6,3,true,78), (6,4,false,49), (6,6,true,63), (6,7,false,47), (6,9,true,82),(7,1,true,98), (7,2,true,96), (7,3,true,92), (7,4,true,91), (7,5,true,96), (7,6,true,99), (7,7,true,93), (7,8,true,99), (7,9,true,94), (7,10,true,98),(8,1,false,32), (8,2,false,33), (8,3,false,42), (8,4,false,43), (8,7,false,52), (8,9,false,53),(9,1,false,36), (9,2,false,39), (9,3,false,56), (9,4,false,55), (9,7,false,55), (9,9,false,51),(10,1,true,86), (10,2,true,88), (10,3,true,92), (10,4,true,100), (10,5,true,100), (10,6,true,100), (10,7,false,100), (10,8,true,100), (10,9,true,100), (10,10,true,100); 1.2 Mysql逻辑分层结构&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先确定一个概念，通常开发中操作的是Mysql Client客户端，与Client相连并且处理数据和存储数据的称为Mysql Server或者Database Manager System（DBMS），Client职责就是输入并发送给Server处理，所以这里我们只讨论Server的逻辑分层结构。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从上图大体可以看出来，按逻辑共分为四层，概括一下包含：连接层、服务层、数据驱动层（引擎层）和数据层。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;① 连接层被设计为连接池形式，主要负责与Client的通信，同时提供授权和安全等策略； &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;② 服务层是Mysql Server的核心结构，主要包括：管理服务、SQL接口、SQL解析器、SQL优化器和缓存，具体介绍请看下一段。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;③ 数据驱动层（引擎层）是由Mysql提供的插件式数据引擎套件，按照业务实际需要选择合适的引擎，将会很大程度上提高算力。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;④ 数据层主要是物理层次的数据及相关信息的存储，例如慢查询日志等。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在服务层中，管理服务主要负责备份、恢复、数据迁移、集群等操作；SQL接口主要负责最熟悉的DML、DDL、存储过程、视图和触发器等处理；SQL解析器主要负责语法解析；SQL优化器主要负责重写系统判定不够优化的语句，也就是说，当我们通过Client提交一个SQL之后，优化器可能会对我们的SQL等效重写并继续向下执行，重写后的语句是Server认为足够优化的语句。SQL缓存将在之后章节具体介绍。 由于SQL优化器的存在，我们写的SQL并不一定是Server执行的SQL。 1.3 DQL执行顺序与SQL优化器 DQL : Data Query Language 数据查询语言，特指Select及相关的(group by etc.)操作统称。 DML : Data Manipulation Language 数据操作语言，包含INSERT、DELETE、UPDATE。 DDL : Data Defination Language 数据定义语言，包含CREATE、 DROP等。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在数据库DQL中，存在一条线性的关键字匹配和处理流程，这里所说的关键字就是与数据库操作有关的系统关键字。首先看下列关键字序列： 123456789101112131415SELECT DISTINCT &lt; select_list &gt;FROM &lt; left_table &gt; &lt; join_type &gt; JOIN &lt; right_table &gt; ON &lt; join_condition &gt;WHERE &lt; where_condition &gt;GROUP BY &lt; group_by_list &gt;HAVING &lt; having_condition &gt;ORDER BY &lt; order_by_condition &gt;LIMIT &lt; limit_number &gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这是一条日常开发中涉及较多关键字的SQL，也是SQL解析器认为合法的表示流程，但实际上，SQL解析器解析之后是按照如下顺序执行： 12345678910FROM &lt;left_table&gt;ON &lt;join_condition&gt;&lt;join_type&gt; JOIN &lt;right_table&gt;WHERE &lt;where_condition&gt;GROUP BY &lt;group_by_list&gt;HAVING &lt;having_condition&gt;SELECT DISTINCT &lt;select_list&gt;ORDER BY &lt;order_by_condition&gt;LIMIT &lt;limit_number&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;掌握Mysql执行过程很重要，因为在后续优化过程中，经常需要确定驱动表以及多表查询时的执行顺序影响效率问题。 简化表示：FROM…ON…JOIN…WHERE…GROUP BY… HAVING…SELECT…DISTINCT…ORDER BY…LIMIT 简单来说，就是按顺序找到表，再从表中抽数据，再组织数据 2 代码级优化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;代码级优化是指，针对手写或者ORM框架生成的原生SQL语句进行优化，优化目的是产生运行效率更高的执行语句。多数情况下，我们针对DQL进行优化。 2.1 使用联接代替子查询&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;子查询是指，使用SELECT查询出目标结果集，然后将该结果集当作其他查询的过滤条件使用。换句话说就是一个SELECT查询中的WHERE条件嵌套另一个或多个SELECT语句，这种写法不仅将多个逻辑联系起来更符合自然逻辑，而且避免了执行中的死锁和事务安全问题，但是，在执行过程中，Mysql会对子查询创建临时表，这就增加了IO消耗。 例：查询选修了Python课程的学生信息。 123456SELECT * FROM `tb_student`WHERE id IN ( SELECT student_id FROM `tb_student_course` WHERE course_id IN ( SELECT id FROM `tb_course` WHERE name = 'Python')); 声明：为了方便，使用SELECT *写法，实际业务处理中应使用具体字段SELECT id, name, age写法。 上述例子中，使用了三层SELECT语句组成的完整查询，逻辑清晰但实际运行效率并不高，下面改成JOIN写法。 12345SELECT t1.* FROM `tb_student` t1 JOIN `tb_student_course` t2 ON t1.id = t2.student_id JOIN `tb_course` t3ON t2.course_id = t3.idWHERE t3.name = 'Python'; 或者 123SELECT t1.* FROM `tb_student` t1, `tb_student_course` t2, `tb_course` t3 WHERE t1.id = t2.student_id AND t2.course_id = t3.id AND t3.name = 'Python'; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在排除SQL优化器和缓存条件（重复执行，效率会提高）时，从执行时间来看，后两者效率明显比前者效率高。 2.2 删除操作2.2.1 DELETE、DROP和TRUNCATE的区别 DELETE属于DML，执行操作时，每次从目标表中删除一行数据，并且删除行为作为日志保存以便进行”恢复“操作；而DROP和TRUNCATE属于DDL，其操作不能回滚。 DELETE时会执行相关的触发器，并且执行之后需要显示的commit才能完成删除动作[1]；而DROP和TRUNCATE会隐式commit，且不会执行触发器。 DROP删除表中所有数据，并释放表空间；TRUNCATE删除表中所有数据，重置高水位（high watermark）[2]；DELETE逐行删除，高水位保持不变。 [1] : 在Mysql中，默认DML开启了自动提交，所以执行DML之后无需commit，但并不代表它是隐式执行，可以通过SHOW VARIABLES LIKE 'autocommit'查看。 [2] : 举个例子，例如表中id主键自增且当前id=10，当DELETE 全表之后再新增，id为11；而TRUNCATE和DROP之后再新增，id=1。 2.2.2 DELETE大数据量优化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;DELETE删除大数据量后，不仅产生了许多日志空间，且所删除的空间并未被释放，此时需要使用OPTIMIZE TABLE [数据库]来释放。 123DELETE FROM `tb_student_course`;OPTIMIZE TABLE `tb_student_course`; 2.3 避免使用SELECT * 使用SELECT *会查询全表字段作为结果集，当我们只需要部分而不是全部字段作为结果集时，就会造成资源浪费，不仅降低了查询效率，还增加了网络IO使用率；当多人维护表时，如果表字段发生变化（增加或者删除）就会造成预期外的结果，或者需要额外的后台代码进行过滤，不利于维护。 安全性考虑，如果发生SQL注入风险，有可能被攻击者创建联表条件，从而更多信息被暴露。 SELECT 目标列正好是索引时，会更快的从内存（B+Tree）中读取数据并返回而不产生本地IO。 【本条转自】：https://blog.csdn.net/u013240038/article/details/90731874 连接查询时， 无法进入缓冲池查询。 每次驱动表加载一条数据到内存中，然后被驱动表所有的数据都需要往内存中加载一遍进行比较。效率很低，所以mysql中可以指定一个缓冲池的大小，缓冲池大的话可以同时加载多条驱动表的数据进行比较，放的数据条数越多io操作就越少，性能也就越好。所以，如果此时使用select 放一些无用的列，只会白白的占用缓冲空间。浪费本可以提高性能的机会。 2.4 分页优化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据库层级的分页优化，实际上就是针对LIMIT关键字的优化，Mysql支持的LIMIT关键字系统中可以用作分页处理，表达式：LIMIT offset,rows 或 LIMIT rows。比如LIMIT 123456,50，从123456行开始查询50条数据；LIMIT 50将查询结果取前50条数据。LIMIT虽然使用方便但在大数据量时就会出现性能问题，随着offset增大，性能急剧下降，究其原因是因为LIMIT 123456,50会先扫描123456+50=123506条数据，然后返回50条，额外扫描的123456并不是我们需要的，事实上这样的设计显得多余，当数据量级增加之后，性能必然骤降。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;优化方式一：从实际情况来看，受影响的似乎只有LIMIT offset, rows形式，而LIMIT rows并不影响性能，实际上后者只扫描rows行数据，所以我们可以进行如下替换： 12345SELECT * FROM table LIMIT 123456,50;#LIMIT扫描123506条数据#转换后SELECT * FROM table WHERE id &gt;= 123456 LIMIT 50;#LIMIT只扫描50条数据 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;优化方式二：使用覆盖索引，在后续介绍索引时将深入介绍，在此简单提一下：覆盖索引是指，查询列正好全部具有索引，则结果直接从B+Tree中获取而不用回表操作。比如SELECT col1 FROM tb_test LIMIT 123456,50；，正好col1具有索引，那么执行该语句的时候会直接从col1索引对应的数据结构中获得结果，而不用回表到tb_test中再次查询，减少了磁盘IO。 12ALTER TABLE `tb_test` ADD INDEX col1_index(col1);SELECT col1 FROM tb_test LIMIT 123456, 50; 注：创建表并添加主键之后，会自动创建主键索引 Primary Key Index。 2.5 JOIN时使驱动表为小数据量表&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在前文中我们已经提到使用JOIN代替子查询可以明显提高效率，但JOIN本身也有需要更进一步的优化。首先介绍一下JOIN的原理：将驱动表的查询结果作为“输入”，当作条件逐条的在被驱动表内进行过滤，最终返回过滤后的数据，这种JOIN的方式被称作NEST LOOP。 1234567SELECT t1.* FROM tabel1 t1 LEFT JOIN table2 t2 ON t1.condition = t2.conditionJOIN table3 t3ON t1.condition = t3.condition AND t2.condition = t3.conditionWHERE ....ORDER BY t2.id DESC; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这是一个相对复杂的例子，其中用到了LEFT JOIN和JOIN，解析一下过程：将table1当作驱动表查询并返回结果result1，将result1当作被驱动表t2的“输入”，并将result1中的数据逐条取出在table2中匹配，并将最终的结果返回result2，将table1和table2联合查询后的结果result2当作table3的”输入“，并逐条匹配并返回最终结果result3，排序后当作最终的结果返回。所以在使用多表JOIN时，明确表的数据条的多少，有助于我们确定使用小表作为驱动表，从而减少循环次数，达到优化的目的。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;庆幸的是，在不显式地指定驱动表时，SQL优化器帮助我们将最小的表作为驱动表来执行，所谓显式指定是指LEFT JOIN时左侧表为驱动表，RIGHT JOIN时右侧表为驱动表，而JOIN属于隐式，SQL优化器会自行决定小表为驱动表。 思考：上述SQL还存在严重影响性能的地方，可以先做思考，将在后续索引章节介绍。 2.6 避免使用LIKE和正则匹配 题：找出年龄是5或5的倍数的所有老师信息。 使用LIKE关键字查找如下： 12SELECT * FROM tb_teacherWHERE age LIKE \"%5\" OR age LIKE \"%0\"; 使用正则表达式如下： 12SELECT * FROM tb_teacherWHERE age REGEXP \".5|0\"; 两者效果等价，结果如下： id name age course_id 1 老张 55 1 4 老赵 45 4 5 老吴 35 5 6 老孙 45 6 7 老刘 40 7 可以看到LIKE和正则在进行内容过滤检索时很灵活，也很方便，但是 这两者查询都是基于全表的查询，大数据量时查询效率很低，所以给出一下两种解决办法。 当使用MyISAM引擎时，建议使用全文索引FULLTEXT，因为只有MyISAM引擎是支撑该特殊索引方式的，所以可以在创建表的时候使用FULLTEXT(字段)来定义，如下： 1234567CREATE table `tb_student`( id int primary key auto_increment, name varchar(20), age int, description text, FULLTEXT(description))ENGINE = Myisam CHARACTER SET = utf8; Mysql会创建索引表维护该索引列，查询时使用如下方式： 1SELECT * FROM tb_student WHERE MATCH(description) AGAINST('关键字'); 当业务中不得不实现LIKE模糊匹配时，最好在匹配字符中不以占位符开始LIKE '关键字%'，这样可以使查询字段的索引生效，相反则会索引失败进行全表查询；如果不得不以占位符开始，那么可以使用覆盖索引来提高效率。","link":"/2020/02/12/2 MySQL/MySQL优化系列（一）/"},{"title":"MySQL优化系列（三）","text":"MySQL优化系列（三） 3.2 EXPLAIN 执行计划&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;执行计划的查看是进行SQL调优的重要步骤，也是收集可调优选项的信息集中地，Mysql中通过关键EXPLAIN来查看SELECT的查询效率。我们已经知道在逻辑分层中，服务层存在SQL优化器，它可以对我们的SQL进行优化并最终在引擎中执行，EXLAIN可以模拟SQL优化器执行结果。 3.2.1 使用和介绍1EXPLAIN SELECT * FROM `tb_course`\\G 该语句将模拟优化器执行，并将执行信息打印在控制台，如下： 1234567891011121314mysql&gt; EXPLAIN SELECT * FROM tb_course \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb_course partitions: NULL type: indexpossible_keys: NULL key: union_index key_len: 70 ref: NULL rows: 14 filtered: 100.00 Extra: Using index [id]： SELECT执行语句的编号，是一组整型数值。① 当Explain某一复杂语句时，可能包含多条子查询，那么查询顺序按照编号由大到小执行；② 当查询编号一致时，按照从上到下的顺序执行。例1：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 mysql&gt; EXPLAIN SELECT * FROM tb_student WHERE id IN (SELECT student_id FROM tb_student_course WHERE course_id=(SELECT id FROM tb_course WHERE name=&apos;JAVA&apos;) ) \\G *************************** 1. row *************************** id: 1 select_type: PRIMARY table: &lt;subquery2&gt; partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: NULL filtered: 100.00 Extra: NULL*************************** 2. row *************************** id: 1 select_type: PRIMARY table: tb_student partitions: NULL type: eq_refpossible_keys: PRIMARY key: PRIMARY key_len: 4 ref: &lt;subquery2&gt;.student_id rows: 1 filtered: 100.00 Extra: NULL*************************** 3. row *************************** id: 2 select_type: MATERIALIZED table: tb_student_course partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 1 filtered: 100.00 Extra: Using where*************************** 4. row *************************** id: 3 select_type: SUBQUERY table: tb_course partitions: NULL type: refpossible_keys: union_index key: union_index key_len: 63 ref: const rows: 5 filtered: 100.00 Extra: Using index4 rows in set, 1 warning (0.04 sec)该用例中查询序列按照3 -&gt; 2 -&gt; 1 -&gt; 1执行，首先查询SELECT id FROM tb_course WHERE name='JAVA'接着将子查询结果作为条件执行SELECT student_id FROM tb_student_course WHERE course_id=subquery，SQL优化器将最后主查询SELECT * FROM tb_student WHERE id IN (subquery) 与上一步子查询进行联接，先查询student_id，再查询最终结果。例2：1234567891011121314151617181920212223242526272829#查询选修了Java的学生课程关联表mysql&gt; EXPLAIN SELECT * FROM tb_student_course WHERE course_id IN (SELECT id FROM tb_course WHERE name LIKE &apos;JAVA%&apos;) \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb_student_course partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 1 filtered: 100.00 Extra: NULL*************************** 2. row *************************** id: 1 select_type: SIMPLE table: tb_course partitions: NULL type: eq_refpossible_keys: PRIMARY,union_index key: PRIMARY key_len: 4 ref: optdemo.tb_student_course.course_id rows: 1 filtered: 35.71 Extra: Using where该例子中应当属于子查询嵌套类型且id顺序不一致，只是SQL优化器进行了优化，将嵌套查询优化为联接，所以编号一致，执行顺序从上到下。[select_type]：表示查询类型：Simple简单查询，Primary外侧主查询，Subquery内测子查询，Derived驱动查询表示当前语句位于FROM后，Materialized被物化的子查询。[table]：当前查询所在的目标表。[partitions]：查询目标是分区表的位置，如果查询目标在其他分区的表中将显示出来。在早先Mysql版本中，需要使用Exlain Extends才会显示该选项。[type]：访问类型，用于判断当前查询优化类别，是单表优化的重要指标，type效率指标由优到差依次为：system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; all- system : 查询结果只有一条数据，且扫描表中数据也只有一条，WHERE后使用主键索引查询。- const : 查询结果只有一条数据，且扫面表中有多条数据，WHERE后使用主键索引查询，system是const的特殊情况。- eq_ref : 查询结果为多条数据，使用唯一索引或主键索引查询。- ref : 查询结果为多条数据，使用普通索引或复合索引查询。- range : 查询结果为多条数据，使用索引查询且是范围索引，如使用&gt;、&lt;、BETWEEN、AND、OR、IN等- index : 查询结果为多条数据，使用索引查询，但对索引表进行全表扫描。- all : 查询结果为多条数据，未使用索引，对全表数据扫描。一般来说，在实际业务中，system和const情况几乎不可能达到，而index和all的效率过低是主要的被优化目标，而期望的优化目标则为eq_ref、ref，range情况特殊它属于范围内的索引表扫描，实际优化应考虑索引扫描范围。[possible_keys]： SQL优化器执行前预估的索引类型。[key]： 实际执行时用到的索引类型。[key_len]： 实际使用的索引长度，用于确认用到的索引。[ref]： 联接查询时的联接条件[rows]： 返回结果集时，所查询的总行数。[filtered]： 表示返回数据在server层过滤后，剩下多少满足查询的记录数量的百分比，同partition，在5.7版本以前需要使用explain extended查询。[Extra]： 表示查询时额外的说明信息，该字段与type一样，同样时需要优化时特别关注的，常遇到的类型包括：using filesort、using temporary、using index、using where、distinct等，特别需要关注前两项，它们出现是性能损耗过大的表现。- using filesort : 常见于使用order by 排序，由于索引查询后排序并未使用索引字段或索引字段失效，导致排序时将在内存中的“排序空间”进行，排序空间通过sort_buffer_size设置，会额外产生空间和时间的浪费。- using temporary : 常见于group by或order by操作，当查询结果进行分组时会在内存中额外使用“临时表”空间存储和聚合，额外产生空间和时间的浪费，多见于order by或group by字段并非多表查询结果字段。- using index : 表示当前查询使用了索引查询，无需回表查询，性能提升。- using where : 返回的记录并不是所有的都满足查询条件，需要在server层进行过滤，即回表查询，属于“后置过滤”，在版本5.6之后出现了using index condition，它的含义是先在索引表中查询复合索引过滤条件的数据，再将这些数据使用where其他条件进行过滤，与using where相比，将索引过滤提前到索引表内，所以where条件优先设置索引过滤（SQL优化器是否会自动优化还待确认）。- distinct : 表示数据查询后使用了distinct筛查，将查询结果进行二次全部扫描，排除重复项。#### 3.2.2 最左前缀原则&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在复合索引的使用过程中经常提到”最左前缀原则“，它的意思是说，当创建一个复合索引tb_index(col1, col2, col3)，使用索引必须按照严格的定义顺序，比如SELECT * FROM tb WHERE col=x and col2=xx and col3=xxx，这样联合索引才能达到最高效率。如果执行如下破坏顺序索引的例子将不能完全发挥索引功能或丧失索引功能：SELECT * FROM tb WHERE col1=x and col3=xxx（跳过中间索引col2，只有col1生效，col3无法使用索引），SELECT * FROM tb WHERE col2=xx and col3=xxx(跳过col1，索引全部失效)。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了探讨最左前缀原则的原理，重新回到索引的数据结构，我们已经讨论过无论是MyISAM还是InnoDB引擎都是用B+Tree数据结构进行索引表的保存，不妨以科学疑问的形式提出两种数据结构的假设：1. 一个列代表一个b+tree结构，多个列则分表对应多个b+tree，比如上例提到的复合索引，col1、col2、col3在物理模型上分别对应三个b+tree文件，当执行SELECT * FROM tb WHERE col1=x and col2=xx and col3=xxx时，首先从col1索引表中定位，定位到的data域保存指向col2索引的指针从而在col2对应的索引表中定位，col3同理，最终在col3的叶子节点data域中找到目标结果。2. 在物理模型上只有一个索引文件，即一个b+tree保存联合索引，并在key域中以严格的定义顺序保存多列索引字段按次序依次定位，从而最终获得目标结果。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;先确认第二条为正确结果，那么我们来讨论第一条为什么不是，为什么数据库大多都采用B+Tree作为结构模型而非红黑树之类，主要原因在于索引本身就是一张容量较大的表结构，使用内存是性能损耗和系统稳定性都受点影响的一件事，那么只能考虑作为文件保存在物理磁盘上，而物理磁盘的IO效率又过低容易影响系统整体的吞吐量，所以衡量索引最重要的标准就是在查询中减少磁盘IO的次数，显然第一条假设严重违背了这样的标准，因为如果复合索引的多列分别对应多张索引的话，那么磁盘上的文件也会一一对应，当我们执行覆盖索引的SQL语句时，就代表经过多次磁盘IO，效率很可能反而降低了。#### 3.2.3 避免索引失效&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在索引列上做任何操作(计算、 函数、自动\\手动类型转换)，会导致索引失效而转向全表扫描，究其原因，主要是破坏（不满足）B+Tree索引表的查询条件，以下常见场景需要注意（由于MYSQL优化器在不同版本之间表现不同，所以结果可能有出入）：1. 模糊查询LIKE后接匹配符 % 或 _时，只能出现在最末位置。 当前tb_course表中数据，以及索引情况如下，索引只有主键索引和联合索引union_index(name, is_required, credit)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869mysql&gt; SELECT * FROM tb_course ;+----+-----------------+-------------+--------+| id | name | is_required | credit |+----+-----------------+-------------+--------+| 1 | C | 1 | 4 || 5 | C# | 0 | 2 || 11 | JAVA | 0 | 0 || 12 | JAVA | 1 | 1 || 13 | JAVA | 1 | 2 || 14 | JAVA | 1 | 3 || 2 | JAVA | 1 | 4 || 10 | Linux | 0 | 2 || 6 | Python | 0 | 3 || 8 | TCP/IP | 0 | 2 || 7 | 人工智能 | 1 | 4 || 4 | 操作系统 | 1 | 4 || 3 | 数据结构 | 1 | 3 || 9 | 计算机网络 | 1 | 3 |+----+-----------------+-------------+--------+mysql&gt; SHOW INDEX IN tb_course\\G*************************** 1. row *************************** Table: tb_course Non_unique: 0 Key_name: PRIMARY Seq_in_index: 1 Column_name: id Collation: A Cardinality: 14 Sub_part: NULL Packed: NULL Null: Index_type: BTREE*************************** 2. row *************************** Table: tb_course Non_unique: 1 Key_name: union_index Seq_in_index: 1 Column_name: name Collation: A Cardinality: 10 Sub_part: NULL Packed: NULL Null: YES Index_type: BTREE*************************** 3. row *************************** Table: tb_course Non_unique: 1 Key_name: union_index Seq_in_index: 2 Column_name: is_required Collation: A Cardinality: 11 Sub_part: NULL Packed: NULL Null: YES Index_type: BTREE*************************** 4. row *************************** Table: tb_course Non_unique: 1 Key_name: union_index Seq_in_index: 3 Column_name: credit Collation: A Cardinality: 14 Sub_part: NULL Packed: NULL Null: YES Index_type: BTREE 12345678910111213141516#MySQL 5.7mysql&gt; EXPLAIN SELECT * FROM tb_course WHERE name LIKE &apos;%AVA%&apos;\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb_course partitions: NULL type: indexpossible_keys: NULL key: union_index key_len: 70 ref: NULL rows: 14 filtered: 11.11 Extra: Using where; Using index1 row in set, 1 warning (0.00 sec) 从结果可以看到，最终的执行计划显示使用了联合索引union_index，这是因为在当前测试使用的MYSQL版本为5.7，SQL优化器对%AVA%进行了优化处理使得可以进行索引查询，但在MYSQL5.6之前版本中将显示无法使用索引，执行计划显示使用全局查询，如下： 123456789101112131415#MySQL 5.6mysql&gt; EXPLAIN SELECT * FROM tb_course WHERE name LIKE &apos;%AVA%&apos;\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb_course partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 10 filtered: 11.11 Extra: Using where 建议：尽量使用全文索引，如果必须使用模糊查询，建议匹配条件不以%或_开头。 2. OR的前后字段必须都为索引字段，否则索引失效 当OR前后字段只有一个是索引时，那么全部不使用索引，相反当所有字段是索引时才会使用索引。 123456789101112131415mysql&gt; EXPLAIN SELECT * FROM tb_teacher WHERE id=2 OR name=&apos;老张&apos;\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb_teacher partitions: NULL type: ALLpossible_keys: PRIMARY key: NULL key_len: NULL ref: NULL rows: 10 filtered: 19.00 Extra: Using where1 row in set, 1 warning (0.00 sec) id是主键索引，而name字段无索引，所以结果显示possible_keys: PRIMARY可能使用到主键索引，实际并未使用索引key: NULL。 3. 联合索引需要满足最左原则，否则索引部分失效或全部失效 见 3.2.2 4. 堤防隐式转换破坏索引查询 当字段为varchar类型索引时，如果使用整型类型当作条件查询，则会破坏索引规则，使失效。 1234567891011121314151617181920212223242526272829303132333435363738# 测试新增索引mysql&gt; ALTER TABLE tb_teacher ADD INDEX name_index(name);Query OK, 0 rows affected (0.07 sec)Records: 0 Duplicates: 0 Warnings: 0# 正常mysql&gt; EXPLAIN SELECT * FROM tb_teacher WHERE name=&apos;123&apos; \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb_teacher partitions: NULL type: refpossible_keys: name_index key: name_index key_len: 63 ref: const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec)# 失效mysql&gt; EXPLAIN SELECT * FROM tb_teacher WHERE name=123 \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb_teacher partitions: NULL type: ALLpossible_keys: name_index key: NULL key_len: NULL ref: NULL rows: 11 filtered: 10.00 Extra: Using where1 row in set, 3 warnings (0.00 sec) 建议： 日常开发中在书写SQL时需要细心注意索引字段类型，此类问题一般比较隐蔽。 5. 不等表示( &lt;&gt;, !=) 和 空判断(is null, is not null) 使索引失效 因为不等和为空都不会进入索引表，所以即使针对索引列判断也无法生效，将进行全表扫描。 12345678910111213141516171819202122232425262728293031# 不等操作mysql&gt; EXPLAIN SELECT * FROM tb_teacher WHERE name &lt;&gt; &apos;123&apos; \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb_teacher partitions: NULL type: ALLpossible_keys: name_index key: NULL key_len: NULL ref: NULL rows: 11 filtered: 100.00 Extra: Using where # 为空判断 mysql&gt; EXPLAIN SELECT * FROM tb_teacher WHERE name is not null \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb_teacher partitions: NULL type: ALLpossible_keys: name_index key: NULL key_len: NULL ref: NULL rows: 11 filtered: 100.00 Extra: Using where 注意，possible_keys计划使用name_index索引，实际并未使用索引。 当针对整型类型进行不等操作时，被优化器优化处理： 12345678910111213141516171819202122232425262728293031# 主键索引mysql&gt; EXPLAIN SELECT * FROM tb_teacher WHERE id &lt;&gt; 10 \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb_teacher partitions: NULL type: rangepossible_keys: PRIMARY key: PRIMARY key_len: 4 ref: NULL rows: 10 filtered: 100.00 Extra: Using where # 联合索引mysql&gt; explain select * from tb_course where credit &lt;&gt; 0 \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb_course partitions: NULL type: indexpossible_keys: NULL key: union_index key_len: 70 ref: NULL rows: 14 filtered: 90.00 Extra: Using where; Using index 6. 计算、函数表达式使索引失效 当对索引字段进行函数或计算则有可能使其失效，之所以说有可能同样时因为不同版本中SQL优化器表现不同所致。 1234567891011121314mysql&gt; EXPLAIN SELECT * FROM tb_course WHERE credit*2 &gt; 2 \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb_course partitions: NULL type: indexpossible_keys: NULL key: union_index key_len: 70 ref: NULL rows: 14 filtered: 100.00 Extra: Using where; Using index 可以看到，此处使用了索引查询，也就表示在当前测试版本中优化器进行了优化操作，在MYSQL 5.6之前索引无效。 7. 当全表扫描速度更快时，索引失效 当优化器认为全表扫描速度优于索引查找时，使索引失效，这种场景往往牵扯到创建索引时涉及的块的读取成本问题。 3.2.4 单表优化实战&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了演示单表优化过程，以tb_course为例，首先删除已经存在的索引drop index union_index on tb_course;，再次申明，测试使用的MYSQL当前版本为5.8，不同版本SQL优化器执行计划不一定相同。 查询学分不为0的必修课的名称。 1234567891011121314mysql&gt; EXPLAIN SELECT name FROM tb_course WHERE is_required=1 AND credit &lt;&gt;0 ORDER BY credit DESC \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb_course partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 14 filtered: 9.00 Extra: Using where; Using filesort 当前type为ALL表示未使用索引，最差全表扫描查询。 是否可以将name, is_required, credit设置为联合索引提高效率？ 123456789101112131415161718mysql&gt; ALTER TABLE tb_course ADD INDEX test_index1(name,is_required,credit);Query OK, 0 rows affected (0.05 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; EXPLAIN SELECT name FROM tb_course WHERE is_required=1 AND credit &lt;&gt;0 ORDER BY credit DESC \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb_course partitions: NULL type: indexpossible_keys: NULL key: test_index1 key_len: 70 ref: NULL rows: 14 filtered: 9.00 Extra: Using where; Using index; Using filesort 在当前版本测试中显示type升级为index，Extra新增 Using index项，效率确实有少许提升（在MySQL5.6版本中可能显示任然无法使用索引或索引失效），但没有达到我们优化的目标级别(range以上)，此时我们仔细分析一下：在SQL执行顺序中（1.3章节），执行顺序应该为 FROM &gt; WHERE &gt; SELECT &gt; ORDER BY，所以当前创建的索引test_index1(name,is_required,credit)并没有按照执行顺序执行，换句话说，当前SQL使用的索引顺序是乱序的。 按照执行顺序创建联合索引是否可行？ 12345678910111213141516171819202122mysql&gt; drop index test_index1 ON tb_course;Query OK, 0 rows affected (0.03 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; ALTER TABLE tb_course ADD INDEX test_index2(is_required, credit, name);Query OK, 0 rows affected (0.04 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; EXPLAIN SELECT name FROM tb_course WHERE is_required=1 AND credit &lt;&gt;0 ORDER BY credit DESC \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb_course partitions: NULL type: rangepossible_keys: test_index2 key: test_index2 key_len: 7 ref: NULL rows: 10 filtered: 100.00 Extra: Using where; Using index 很明显可以看到type效率达到了range级别，并且减少了Using filesort这个特别消耗性能的操作。 3.3 ORDER BY排序原理与优化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Mysql版本中ORDER BY的排序算法经过了两代演进，最初使用双路排序算法：将排序字段和对应的行指针从磁盘中读出并在内存中进行排序，遍历该排序列表并从磁盘读取原表匹配返回查询结果。可以看到双路排序算法经过了两次磁盘IO，这在效率上很受影响，属于空间优于时间策略。对应的优化版本则是单路排序算法：将排序字段及其对应的所有查询项一次从磁盘读取获得并在内存中进行排序，排序后的结果即是输出结果，在该算法下将磁盘IO降到最低，对时间效率进行了提升，但同时需要注意多字段读出到内存中，如果数据量巨大则容易导致OOM，如果在系统内存范围内但同样数据量较大则容易产生回表操作，反而不如双路排序算法有优势。在内存中进行排序操作依赖Mysql在内存中创建的缓存区buffer大小，如果数据量超出buffer就会导致创建临时表或回表操作甚至发生OOM，Mysql默认buffer为1024字节，所以预估数据量大小很重要或者使用explain执行计划查看低效率风险，将buffer设置在预估范围边界。 12345678910111213141516mysql&gt; show variables like &quot;max_length_for_sort_data&quot;;+--------------------------+-------+| Variable_name | Value |+--------------------------+-------+| max_length_for_sort_data | 1024 |+--------------------------+-------+mysql&gt; set global max_length_for_sort_data=2048;Query OK, 0 rows affected (0.01 sec)mysql&gt; show variables like &quot;max_length_for_sort_data&quot;;+--------------------------+-------+| Variable_name | Value |+--------------------------+-------+| max_length_for_sort_data | 2048 |+--------------------------+-------+ 以此类比，GROUP BY也是类似问题，只不过优先排序后分组，所以优化策略相同。 3.4 慢查询日志&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在复杂业务场景下，Mysql经常会因为某个复杂查询SQL影响整体性能，甚至出现假死状态，主要原因是因为数据业务量大致使该查询语句耗费太多时间，Mysql提供慢查询日志支持在线网环境下定位具体慢查询语句，默认情况下慢查询处于关闭状态，可以使用指令slow_query_log查看（配置文件开启可以永久生效），通过指定日志文件（默认文件为slow-query-log-file）和设定慢查询时间阈值来截取SQL。 1234567891011121314151617181920212223242526272829303132333435# 查询慢查询开关是否开启mysql&gt; show variables like &quot;slow_query_log&quot; ;+----------------+-------+| Variable_name | Value |+----------------+-------+| slow_query_log | OFF |+----------------+-------+# 开启慢查询mysql&gt; set global slow_query_log=1;Query OK, 0 rows affected (0.02 sec)mysql&gt; show variables like &quot;slow_query_log&quot;;+----------------+-------+| Variable_name | Value |+----------------+-------+| slow_query_log | ON |+----------------+-------+# 查询时间阈值mysql&gt; show variables like &apos;long_query_time&apos;;+-----------------+-----------+| Variable_name | Value |+-----------------+-----------+| long_query_time | 10.000000 |+-----------------+-----------+# 设置时间阈值mysql&gt; set global long_query_time=5;mysql&gt; show variables like &apos;long_query_time&apos;;+-----------------+-----------+| Variable_name | Value |+-----------------+-----------+| long_query_time | 5.000000 |+-----------------+-----------+ 配置my.ini或my.cnf配置慢查询（需重启服务） 12345# 配置文件[mysqld]slow_query_log =1long_query_time=5slow_query_log_file=D:\\\\software\\\\work\\\\mysql-5.7.23-winx64\\\\slowquery.log 1234567891011121314151617181920mysql&gt; show variables like &quot;slow_query_log&quot;;+----------------+-------+| Variable_name | Value |+----------------+-------+| slow_query_log | ON |+----------------+-------+mysql&gt; show variables like &quot;long_query_time&quot;;+-----------------+----------+| Variable_name | Value |+-----------------+----------+| long_query_time | 5.000000 |+-----------------+----------+mysql&gt; show variables like &quot;slow_query_log_file&quot;;+---------------------+----------------------------------------------------+| Variable_name | Value |+---------------------+----------------------------------------------------+| slow_query_log_file | D:\\software\\work\\mysql-5.7.23-winx64\\slowquery.log |+---------------------+----------------------------------------------------+ 通过sleep函数设置睡眠时间来测试： 1mysql&gt; select sleep(6); 手动查看日志 1234567MySQL, Version: 5.7.23-log (MySQL Community Server (GPL)). started with:TCP Port: 3306, Named Pipe: (null)Time Id Command Argument# User@Host: root[root] @ localhost [::1] Id: 3# Query_time: 5.999740 Lock_time: 0.000000 Rows_sent: 1 Rows_examined: 0SET timestamp=1586104027;select sleep(6); 使用mysql提供的慢查询命令mysqldumpslow查看 123# 按照平均时长排序并输出前十项C:\\Users\\zhy&gt;mysqldumpslow.pl -s at -t 10 D:\\software\\work\\mysql-5.7.23-winx64\\slowquery.log# mysqldumpslow.pl需要安装perl环境才能使用 3.5 使用Profiling&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;除了使用Explain执行计划查看单个SQL的执行效率外，还可以通过Profiling来查看当前会话中多条SQL的执行性能，主要指标是CPU、BLOCK IO、CONTEXT SWITCH、MEMORY、SWAPS等。 CPU：显示CPU使用相关开销 BLOCK IO：阻塞IO相关开销 CONTEXT SWITCH：上下文切换相关开销 MEMORY：内存相关开销 SWAPS：交换之间的开销 默认情况下是关闭的，可以开启并显示最近执行的SQL 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292# 查看开关和历史记录数mysql&gt; show variables like &apos;profiling%&apos;;+------------------------+-------+| Variable_name | Value |+------------------------+-------+| profiling | OFF || profiling_history_size | 15 |+------------------------+-------+# 设置开关和记录数mysql&gt; set global profiling=1;mysql&gt; set global profiling_history_size=20;mysql&gt; show variables like &apos;profiling%&apos;;+------------------------+-------+| Variable_name | Value |+------------------------+-------+| profiling | ON || profiling_history_size | 20 |+------------------------+-------+# 查看最近的执行SQLmysql&gt; show profiles;+----------+------------+----------------------------------+| Query_ID | Duration | Query |+----------+------------+----------------------------------+| 1 | 0.00040300 | select @@version_comment limit 1 || 2 | 0.00438400 | show variables like &apos;profiling%&apos; || 3 | 0.00018800 | show version() || 4 | 0.00028400 | select version() || 5 | 0.00044975 | show engines || 6 | 0.00034125 | SELECT DATABASE() || 7 | 0.00255175 | select * from tb_teacher |+----------+------------+----------------------------------+# 查看Query_ID为7的所有性能信息*************************** 1. row *************************** Status: starting Duration: 0.000211 CPU_user: 0.000000 CPU_system: 0.000000 Context_voluntary: NULLContext_involuntary: NULL Block_ops_in: NULL Block_ops_out: NULL Messages_sent: NULL Messages_received: NULL Page_faults_major: NULL Page_faults_minor: NULL Swaps: NULL Source_function: NULL Source_file: NULL Source_line: NULL*************************** 2. row *************************** Status: checking permissions Duration: 0.000016 CPU_user: 0.000000 CPU_system: 0.000000 Context_voluntary: NULLContext_involuntary: NULL Block_ops_in: NULL Block_ops_out: NULL Messages_sent: NULL Messages_received: NULL Page_faults_major: NULL Page_faults_minor: NULL Swaps: NULL Source_function: check_access Source_file: sql_authorization.cc Source_line: 810*************************** 3. row *************************** Status: Opening tables Duration: 0.001980 CPU_user: 0.000000 CPU_system: 0.000000 Context_voluntary: NULLContext_involuntary: NULL Block_ops_in: NULL Block_ops_out: NULL Messages_sent: NULL Messages_received: NULL Page_faults_major: NULL Page_faults_minor: NULL Swaps: NULL Source_function: open_tables Source_file: sql_base.cc Source_line: 5685*************************** 4. row *************************** Status: init Duration: 0.000026 CPU_user: 0.000000 CPU_system: 0.000000 Context_voluntary: NULLContext_involuntary: NULL Block_ops_in: NULL Block_ops_out: NULL Messages_sent: NULL Messages_received: NULL Page_faults_major: NULL Page_faults_minor: NULL Swaps: NULL Source_function: handle_query Source_file: sql_select.cc Source_line: 121*************************** 5. row *************************** Status: System lock Duration: 0.000012 CPU_user: 0.000000 CPU_system: 0.000000 Context_voluntary: NULLContext_involuntary: NULL Block_ops_in: NULL Block_ops_out: NULL Messages_sent: NULL Messages_received: NULL Page_faults_major: NULL Page_faults_minor: NULL Swaps: NULL Source_function: mysql_lock_tables Source_file: lock.cc Source_line: 323*************************** 6. row *************************** Status: optimizing Duration: 0.000004 CPU_user: 0.000000 CPU_system: 0.000000 Context_voluntary: NULLContext_involuntary: NULL Block_ops_in: NULL Block_ops_out: NULL Messages_sent: NULL Messages_received: NULL Page_faults_major: NULL Page_faults_minor: NULL Swaps: NULL Source_function: JOIN::optimize Source_file: sql_optimizer.cc Source_line: 151*************************** 7. row *************************** Status: statistics Duration: 0.000016 CPU_user: 0.000000 CPU_system: 0.000000 Context_voluntary: NULLContext_involuntary: NULL Block_ops_in: NULL Block_ops_out: NULL Messages_sent: NULL Messages_received: NULL Page_faults_major: NULL Page_faults_minor: NULL Swaps: NULL Source_function: JOIN::optimize Source_file: sql_optimizer.cc Source_line: 367*************************** 8. row *************************** Status: preparing Duration: 0.000017 CPU_user: 0.000000 CPU_system: 0.000000 Context_voluntary: NULLContext_involuntary: NULL Block_ops_in: NULL Block_ops_out: NULL Messages_sent: NULL Messages_received: NULL Page_faults_major: NULL Page_faults_minor: NULL Swaps: NULL Source_function: JOIN::optimize Source_file: sql_optimizer.cc Source_line: 475*************************** 9. row *************************** Status: executing Duration: 0.000003 CPU_user: 0.000000 CPU_system: 0.000000 Context_voluntary: NULLContext_involuntary: NULL Block_ops_in: NULL Block_ops_out: NULL Messages_sent: NULL Messages_received: NULL Page_faults_major: NULL Page_faults_minor: NULL Swaps: NULL Source_function: JOIN::exec Source_file: sql_executor.cc Source_line: 119*************************** 10. row *************************** Status: Sending data Duration: 0.000078 CPU_user: 0.000000 CPU_system: 0.000000 Context_voluntary: NULLContext_involuntary: NULL Block_ops_in: NULL Block_ops_out: NULL Messages_sent: NULL Messages_received: NULL Page_faults_major: NULL Page_faults_minor: NULL Swaps: NULL Source_function: JOIN::exec Source_file: sql_executor.cc Source_line: 195*************************** 11. row *************************** Status: end Duration: 0.000042 CPU_user: 0.000000 CPU_system: 0.000000 Context_voluntary: NULLContext_involuntary: NULL Block_ops_in: NULL Block_ops_out: NULL Messages_sent: NULL Messages_received: NULL Page_faults_major: NULL Page_faults_minor: NULL Swaps: NULL Source_function: handle_query Source_file: sql_select.cc Source_line: 199*************************** 12. row *************************** Status: query end Duration: 0.000010 CPU_user: 0.000000 CPU_system: 0.000000 Context_voluntary: NULLContext_involuntary: NULL Block_ops_in: NULL Block_ops_out: NULL Messages_sent: NULL Messages_received: NULL Page_faults_major: NULL Page_faults_minor: NULL Swaps: NULL Source_function: mysql_execute_command Source_file: sql_parse.cc Source_line: 4937*************************** 13. row *************************** Status: closing tables Duration: 0.000009 CPU_user: 0.000000 CPU_system: 0.000000 Context_voluntary: NULLContext_involuntary: NULL Block_ops_in: NULL Block_ops_out: NULL Messages_sent: NULL Messages_received: NULL Page_faults_major: NULL Page_faults_minor: NULL Swaps: NULL Source_function: mysql_execute_command Source_file: sql_parse.cc Source_line: 4989*************************** 14. row *************************** Status: freeing items Duration: 0.000107 CPU_user: 0.000000 CPU_system: 0.000000 Context_voluntary: NULLContext_involuntary: NULL Block_ops_in: NULL Block_ops_out: NULL Messages_sent: NULL Messages_received: NULL Page_faults_major: NULL Page_faults_minor: NULL Swaps: NULL Source_function: mysql_parse Source_file: sql_parse.cc Source_line: 5594*************************** 15. row *************************** Status: cleaning up Duration: 0.000022 CPU_user: 0.000000 CPU_system: 0.000000 Context_voluntary: NULLContext_involuntary: NULL Block_ops_in: NULL Block_ops_out: NULL Messages_sent: NULL Messages_received: NULL Page_faults_major: NULL Page_faults_minor: NULL Swaps: NULL Source_function: dispatch_command Source_file: sql_parse.cc Source_line: 1924 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107# 使用具体的性能分类，比如cpu和block iomysql&gt; show profile cpu,block io for query 7 \\G*************************** 1. row *************************** Status: starting Duration: 0.000211 CPU_user: 0.000000 CPU_system: 0.000000 Block_ops_in: NULLBlock_ops_out: NULL*************************** 2. row *************************** Status: checking permissions Duration: 0.000016 CPU_user: 0.000000 CPU_system: 0.000000 Block_ops_in: NULLBlock_ops_out: NULL*************************** 3. row *************************** Status: Opening tables Duration: 0.001980 CPU_user: 0.000000 CPU_system: 0.000000 Block_ops_in: NULLBlock_ops_out: NULL*************************** 4. row *************************** Status: init Duration: 0.000026 CPU_user: 0.000000 CPU_system: 0.000000 Block_ops_in: NULLBlock_ops_out: NULL*************************** 5. row *************************** Status: System lock Duration: 0.000012 CPU_user: 0.000000 CPU_system: 0.000000 Block_ops_in: NULLBlock_ops_out: NULL*************************** 6. row *************************** Status: optimizing Duration: 0.000004 CPU_user: 0.000000 CPU_system: 0.000000 Block_ops_in: NULLBlock_ops_out: NULL*************************** 7. row *************************** Status: statistics Duration: 0.000016 CPU_user: 0.000000 CPU_system: 0.000000 Block_ops_in: NULLBlock_ops_out: NULL*************************** 8. row *************************** Status: preparing Duration: 0.000017 CPU_user: 0.000000 CPU_system: 0.000000 Block_ops_in: NULLBlock_ops_out: NULL*************************** 9. row *************************** Status: executing Duration: 0.000003 CPU_user: 0.000000 CPU_system: 0.000000 Block_ops_in: NULLBlock_ops_out: NULL*************************** 10. row *************************** Status: Sending data Duration: 0.000078 CPU_user: 0.000000 CPU_system: 0.000000 Block_ops_in: NULLBlock_ops_out: NULL*************************** 11. row *************************** Status: end Duration: 0.000042 CPU_user: 0.000000 CPU_system: 0.000000 Block_ops_in: NULLBlock_ops_out: NULL*************************** 12. row *************************** Status: query end Duration: 0.000010 CPU_user: 0.000000 CPU_system: 0.000000 Block_ops_in: NULLBlock_ops_out: NULL*************************** 13. row *************************** Status: closing tables Duration: 0.000009 CPU_user: 0.000000 CPU_system: 0.000000 Block_ops_in: NULLBlock_ops_out: NULL*************************** 14. row *************************** Status: freeing items Duration: 0.000107 CPU_user: 0.000000 CPU_system: 0.000000 Block_ops_in: NULLBlock_ops_out: NULL*************************** 15. row *************************** Status: cleaning up Duration: 0.000022 CPU_user: 0.000000 CPU_system: 0.000000 Block_ops_in: NULLBlock_ops_out: NULL 应重点关注以下几个情况： converting HEAP to MyISAM ：查询结果太大，内存转磁盘。 Creating tmp table :创建了临时表，性能损耗严重。 Copying to tmp table on disk：把内存中的临时表复制到磁盘，性能损耗严重 locked ：被加锁。","link":"/2020/02/24/2 MySQL/MySQL优化系列（三）/"},{"title":"MySQL优化系列（二）","text":"MySQL优化系列（二） 3 数据库级优化3.1 索引数据结构&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;索引是DQL优化的核心，可以显著提高查询的效率，但值得注意的是凡事有利则有弊，数据检索性能的提高是依赖数据库内部维护的检索表，它是一个B+Tree的数据结构，本身就会占用空间且当对表做出DML操作时，需要同步维护该索引，所以DML的效率则会下降，效果可以类比线性表存储结构。建议对频繁进行数据查询的表创建索引，并选择合适的索引类型，同时以满足业务需求为目的创建，否则会适得其反。 3.1.1 B-Tree&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;B-Tree是数据库中使用最为常见的数据结构，由平衡二叉查找树演化而来，现在多使用的B+Tree结构由B-Tree演化而来，所以有必要先介绍B-Tree。 B-Tree中的B是Balance而非Binary；”B-Tree”和”B+Tree”会被有些人称为”B减树“和”B加树“，这样称呼看似合人情但不合理，因为B-Tree创建之时不可能已经意识到B+Tree的存在，也就不存在名称对立，所以个人认为，“-”只是一个连接符，没有任何含义，应该称为“B树”和“B加树”。 B-Tree并不是二叉树，而是多叉树。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先需要理解，为什么需要B-Tree，这就需要从非关系型数据库的存储来讲，我们在开发过程中通常将MVC分层中数据库DML操作称为“持久化”过程，其实是因为数据库中的数据都是保存在磁盘中的。系统从磁盘读取数据并保存到内存是以“磁盘块（block）”为基础单位，位于同一磁盘块的数据会被一次性加载进来，而不是按需加载。那么，B-Tree的意义就是如何以最优的方式找到数据所在的磁盘块加载需要的数据，减少io损耗。 众所周知，磁盘IO是系统的瓶颈之一，且无法大幅优化提升效率，那么减少IO次数就很关键。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;定义一组普通映射[key, data]，key为索引的键（数据不同则键值不同），data为索引对应的一行表数据。B-Tree数据结构定义如下： 所有叶子节点都在同一层，且没有指向其他节点的指针。 每个非末端节点包含n个关键字或引用，保存每个节点保存更多的信息。 满足平衡二叉树的定义，即节点的索引值大于左子树索引值，小于右子树索引值，但可以有多个子节点。 索引值必包含对应的映射数据信息。 题：以查找索引值51为例，经过的步骤如下： 根节点磁盘块读取并存入内存中，48 &lt; 51，所以指向指针P2的子节点。（1次磁盘IO，1次内存加载） P3指向的磁盘块读取并存入内存，找到目标51并返回对应的行数据。（1次磁盘IO，1次内存加载） 题：以查找索引值15为例，经过的步骤如下： 根节点磁盘块读取并存入内存中，13 &lt; 15 &lt; 48，所以指向指针P2的子节点。（1次磁盘IO，1次内存加载） P2指向的磁盘块读取并存入内存，15 &lt; 20，所以指向指针P1的子节点。（1次磁盘IO，1次内存加载） P1指向的磁盘块读取并存入内存，找到目标15返回对应行数据。（1次磁盘IO，1次内存加载） 经过上述步骤查找，最终经过3次磁盘IO和3次内存加载，定位到索引15并读取的对应的行信息返回。所以在当前索引中最优结果是1次磁盘IO和1次内存加载，即根节点位置定位。最差结果是3次磁盘IO和3次内存加载，相比于平衡二叉树或红黑树等数据结构，由于节点保存的信息较多，所以树的高度偏扁平，这样减少了磁盘IO，从而提高了查找效率。 3.1.2 B+Tree&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;B-Tree虽然已经很适合作为非关系型数据库的索引模型，但它还存在一些弊端：索引根节点是固定的，没必要每次查找都经过1次磁盘IO读取和加载；由于磁盘块容量有限，而节点保存数据会占用节点很大的空间，所以一个磁盘块能够保存的索引个数会减少，导致树高度可能增加；范围查找变得效率不高。所以在此基础之上，B+Tree做到了如下优化: 根节点常驻内存，减少1次IO损耗； 所有非叶子节点只保存索引值或引用，不保存映射数据，扩增节点保存关键信息的能力； 有两个全局指针，一个指向根节点，另一个指向索引值最小的节点（最左叶子节点）。 所有叶子节点保存索引值和映射数据，且叶子节点由单链表关联，指针指向相邻的右兄弟节点，结合第3条信息，这就提供了查找的多样性，可以选择从根节点开始检索树，也可以从顺序链表头开始进行查询，因为有链表的存在，支持范围查询且效率比B-Tree更好。 题：以查找索引值41为例，经过的步骤如下（与B-Tree一致）： 从内存加载根节点，找到 13 &lt; 41 &lt; 48，指向指针P2的节点。 读取磁盘块，找到 20 &lt; 41 &lt; 42，指向指针P2的几点。 读取磁盘块，找到目标并返回对应数据。 题：以查找索引值13为例，过程如下： 内存加载根节点，找到目标13（此时从右指针查找）。 加载磁盘块，13 &lt; 20，指向P1指针节点。 加载磁盘块，找到目标并返回。 注：为什么非叶子节点定位到目标值要从右侧指针查找，查找了大量网络资源都没有找到合适的答案，最终从维基百科和《高性能Mysql》一书中推测而来。欢迎各位交换意见。 3.1.3 扩展：B*Tree&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;B*Tree是B+Tree的优化，进一步要求，在非根非叶子节点各层中的节点之间互相产生指向相邻右兄弟 节点的指针。 3.1.4 聚簇索引、非聚簇索引和辅助索引&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;B+Tree在数据库中的实现方式即为聚簇索引，其含义是指在一张索引表中，既存在索引值同时存在映射数据；在Innodb引擎中使用聚簇索引，在MyISAM引擎中就使用非聚簇索引，其含义是指，在B+Tree结构中叶子节点索引值对应的并不是数据而是数据在数据页中的地址，通过地址就可以直接在内存中获得数据，数据页是管理磁盘块的最小单位；辅助索引是指，在索引表Index1中查找关键字key1时，需要先从索引表Index2中查找关键字key2对应的关键字key1。 3.2 索引的创建与修改&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在我们已经创建的四张表中，都设置了整型自增主键id，Mysql已经自动帮我们添加了主键索引（MySQL 5.7+版本），也就是说当我们使用id查询时是通过主键索引进行查询。索引按照创建方式可以分为：一般索引、唯一索引、复合索引、主键索引和全文索引。其中主键索引属于唯一索引范畴，全文索引已经在2.6章节中进行了介绍，是MyISAM引擎支持的文本类索引，在此不再深入讨论。 3.2.1 一般索引 创建tb_course表时对课程名name添加索引 12345678#创建课程表，包括id，名称，是否必修课，学分CREATE table `tb_course`( id int primary key auto_increment, name varchar(20), is_required boolean, credit int, INDEX course_name_index(name))ENGINE = InnoDB CHARACTER SET = utf8; 执行命令SHOW INDEX FROM tb_course \\G查看当前表的所有索引： 1234567891011121314151617181920212223242526272829mysql&gt; show index from tb_course \\G*************************** 1. row *************************** Table: tb_course Non_unique: 0 Key_name: PRIMARY Seq_in_index: 1 Column_name: id Collation: A Cardinality: 0 Sub_part: NULL Packed: NULL Null: Index_type: BTREE Comment:Index_comment:*************************** 2. row *************************** Table: tb_course Non_unique: 1 Key_name: course_name_index Seq_in_index: 1 Column_name: name Collation: A Cardinality: 0 Sub_part: NULL Packed: NULL Null: YES Index_type: BTREE Comment:Index_comment: 可以看到row1是系统自动添加的主键索引，row2是我们创建的自定义索引。 通过 CREATE 和 ALTER关键字创建索引 123CREATE INDEX course_name_index ON `tb_course`(name);ALTER TABLE `tb_course` ADD INDEX course_name_index(name); 删除索引 1DROP INDEX course_name_index ON `tb_course`; 3.2.2 唯一索引&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;唯一索引与一般索引的不同之处在于，它所持有的字段必须是唯一的，如果是唯一复合索引，那么复合字段必须是唯一的，其他用法一直，只需要将INDEX替换为UNIQE INDEX。 创建tb_course表时对课程名name添加唯一索引 12345678#创建课程表，包括id，名称，是否必修课，学分CREATE table `tb_course`( id int primary key auto_increment, name varchar(20), is_required boolean, credit int, UNIQUE INDEX course_name_index(name))ENGINE = InnoDB CHARACTER SET = utf8; 通过 CREATE 和 ALTER关键字创建唯一索引 123CREATE UNIQUE INDEX course_name_index ON `tb_course`(name);ALTER TABLE `tb_course` ADD UNIQUE INDEX course_name_index(name); 3.2.3 复合索引&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;复合索引语法与一般索引一致，只是持有多个字段。 创建tb_course表时对课程名、是否必修和学分添加复合索引 12345678#创建课程表，包括id，名称，是否必修课，学分CREATE table `tb_course`( id int primary key auto_increment, name varchar(20), is_required boolean, credit int, INDEX union_index(name, is_required, credit))ENGINE = InnoDB CHARACTER SET = utf8; 通过 CREATE 和 ALTER关键字创建复合索引 123CREATE INDEX union_index ON `tb_course`(name, is_required, credit);ALTER TABLE `tb_course` ADD INDEX union_index(name, is_required, credit); 通过命令SHOW INDEX FROM tb_course \\G查看结果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152mysql&gt; show index from tb_course \\G*************************** 1. row *************************** Table: tb_course Non_unique: 0 Key_name: PRIMARY Seq_in_index: 1 Column_name: id Collation: A Cardinality: 0 Sub_part: NULL Packed: NULL Null: Index_type: BTREE Comment:Index_comment:*************************** 2. row *************************** Table: tb_course Non_unique: 1 Key_name: union_index Seq_in_index: 1 Column_name: name Collation: A Cardinality: 0 Sub_part: NULL Packed: NULL Null: YES Index_type: BTREE*************************** 3. row *************************** Table: tb_course Non_unique: 1 Key_name: union_index Seq_in_index: 2 Column_name: is_required Collation: A Cardinality: 0 Sub_part: NULL Packed: NULL Null: YES Index_type: BTREE*************************** 4. row *************************** Table: tb_course Non_unique: 1 Key_name: union_index Seq_in_index: 3 Column_name: credit Collation: A Cardinality: 0 Sub_part: NULL Packed: NULL Null: YES Index_type: BTREE 可以看到row 2.3.4信息中，索引名称相同，都是union_index，并且索引序列Seq_in_index分别是1,2,3，也就是说我们复合索引查找是有序列限制的（最左原则，后续章节介绍）。","link":"/2020/02/22/2 MySQL/MySQL优化系列（二）/"},{"title":"MySQL优化系列（五）（缓存篇）","text":"MySQL优化系列（五）（缓存篇） 4 缓存&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;说明：由于是MySQL优化系列，本篇缓存旨在引导向，并不深入介绍，后续将开篇深入介绍，同样的，作为Java端持久化框架Mybatis、Hibernate和 JPA 也适用此说明，由于JPA基于Hibernate轻量化封装，所以框架缓存策略选择JPA介绍即可。 4.1 为什么使用缓存&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;缓存，是以提升数据响应为目的，以合理的缓存策略为条件，以数据中间件的形式为手段的一种技术。在计算机纵向世界，软硬件都有各自的缓存，并且缓存都是以提升现有框架约束的性能为价值，且成为衡量系统性能的重要指标之一。再此我们仅讨论软件领域以内存为驱动模型的缓存。 缓存的用途，使用缓存可以减少某条频繁进行数据处理链路上的性能损耗，通常是读多写少的场景，缓存是一种空间换时间的解决方案，通常在内存中进行。 缓存的位置，众所周知，在计算机科学发展历史长河中，困难的问题往往都是通过增加第三方中间件来解决的，而缓存的位置随着业务覆盖的不同而不同。 比如，在web前端页面，经常会缓存页面渲染或数据处理常用的信息，如多次浏览同一商品的信息，这一功能现代浏览器基本都支持。 比如，还是web前端，用户通过点击页面按钮多次进行查询，通过http访问后端控制器接口就可以添加相应的缓存，而无需经过服务层乃至持久层查询。 再比如，数据频繁的读场景，通常是在业务层和持久层中添加缓存，以减少数据库访问带来的IO性能损耗和数据连接开销。 缓存的分类，应用开发层面的数据结构如Map，持久层数据中间件如EhCache、Memcache、Redis等，数据库自带的缓存特性如Mysql和Oracle等。 缓存的策略，由于不同系统的数据访问模式不同，同一种缓存策略很难在不同的数据访问模式下取得满意的性能，通常使用如下几种策略： 基于访问的时间：按各缓存项被访问时间来组织缓存队列，决定替换对象。如 FIFO，LRU； 基于访问频率：用缓存项的被访问频率来组织缓存。如 LFU、LRU2； 访问时间与频率兼顾：兼顾访问时间和频率，使数据在变化时缓存策略仍有较好性能。多数此类算法具有一个可调或自适应参数，通过该参数的调节使缓存策略在基于访问时间与频率间取得一个平衡，如 FBR； 基于访问模式：某些应用有较明确的数据访问特点，进而产生与其相适应的缓存策略。 FIFO，First In Last Out，即先进先出，如果一个数据是最先进入的，那么可以认为在将来它被访问的可能性很小，当缓存空间不足，它最先被释放。 LRU：Least Recently Use，即最近最久未使用算法，选择最近最久未使用的数据予以淘汰，在缓存空间内，最近一直没有被使用的数据会被释放，由新访问数据代替 LFU：Least Frequently Used，即最近最少使用算法，如果一个数据在最近一段时间很少（频率）被访问到，那么可以认为在将来它被访问的可能性也很小。因此，当空间满时，最小频率访问的数据最先被释放。 LRU2：Least Recently Used 2，即LRU的改进版本，每当一次缓存记录的使用，会把它放到栈的顶端。当栈满了的时候，再把栈底的对象给换成新进来的对象。 FBR：Frequency-based replacement， 需要可调参数平衡访问时间和频率。 数据一致性，当分布式缓存中读写并发执行，有可能导致同一数据先读后写，那么缓存中保存的将是旧数据；先操作数据库，再清除缓存，如果缓存删除失败，就会出现数据不一致问题，解决方案如下： 前者可以采取将读写纳入同一节点的缓存按照同步处理，或者采取数据写入前后一并删除相关缓存。 缓存删除失败，可以将删除失败的key存入队列中并重复删除直到成功为止。 缓存的指标，命中率=命中次数/访问次数，命中率是缓存最重要的指标，它直接决定了缓存设计的合理性，若查询一个缓存，十次查询九次能得到正确结果，那么命中率就是90%。而直接影响缓存命中率的因素包含：缓存容量、内存空间和缓存策略。 4.2 MySQL缓存&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从前面介绍已经可以了解到，Mysql在执行时需要经过四层逻辑分层（客户端接口 -&gt; 服务 -&gt; 引擎 -&gt; 持久层），并在服务层和插件引擎层还需要经过解析、优化、执行过程，并最终在持久层完成IO操作，这一些列耗时耗力的操作在QPS峰值时是噩梦般的存在，所以Mysql自身也支持缓存策略，在MyIsam中使用缓存策略，在InnoDB中使用缓冲池策略。 12345678910111213141516171819202122# 查询是否支持查询缓存mysql&gt; show variables like &apos;have_query_cache&apos;;+------------------+-------+| Variable_name | Value |+------------------+-------+| have_query_cache | YES |+------------------+-------+# 查询当前缓存状态mysql&gt; show status like &apos;%qcache%&apos;;+-------------------------+-------+| Variable_name | Value |+-------------------------+-------+| Qcache_free_blocks | 0 | 缓存空闲的内存块| Qcache_free_memory | 0 | 在query_cache_size设置的缓存中的空闲的内存| Qcache_hits | 0 | 缓存的命中次数| Qcache_inserts | 0 | 查询缓存区此前总共缓存过多少条查询命令的结果| Qcache_lowmem_prunes | 0 | 查询缓存区已满而从其中溢出和删除的查询结果的个数| Qcache_not_cached | 0 | | Qcache_queries_in_cache | 0 | 缓存查询次数| Qcache_total_blocks | 0 | 缓存总的内存块+-------------------------+-------+ 通过修改mysql配置文件来配置缓存 1234[mysqld]query_cache_type=1 #0不使用，1使用，2适时使用query_cache_size=10485760 #10M，单位字节query_cache_limit=1048576 #1M, 单个查询允许使用的最大缓存 4.3 Memcache和Redis&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;缓存界两位翘楚，都是基于内存的存储机制，亦可称为内存数据库。两者都是高性能的分布式缓存，在缓存层面都可以很好的满足业务要求。 4.3.1 Memcache&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Memcache是一套分布式的高速缓存系统，对于大型的需要频繁访问数据库的网站访问速度提升效果十分显著，以提升网站的访问速度。通过在内存里维护一个统一的巨大的hash表，它能够用来存储各种格式的数据，包括图像、视频、文件以及数据库检索的结果等。简单来说就是将数据调用到内存中，然后从内存中读取，从而提高读取速度。Memcached是以守护线程方式运行于一个或多个服务器中，随时接收客户端的连接和操作。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于完全依赖内存，使Memcache的容量根据部署节点的内存而定，在32位系统中容量最大限定2G。由于在内存中维护一个Hash表结构来缓存数据，所以它的数据保存形式遵从K-V简单结构，key默认最大不能超过128个字 节，value默认大小是1M，不过可以针对每条数据设定过期策略。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Memcache操作也相对简单，针对Hash表常用的操作如：set设置、get读取、replace替换、delete删除和flush刷新等。目前只支持文本类型的存取，所以在面向对象中可以将需要存储的对象经过序列化处理并保存，读取之后可以通过反序列化还原。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Memcache采用LRU过期策略，不支持持久化，所以当内存断电时会发生数据丢失，且无备份功能。 123456789101112131415161718192021222324252627282930/* Java 调用Memcache */public class MemcachedJava { public static void main(String[] args) { try{ // 连接本地的 Memcached 服务 MemcachedClient mcc = new MemcachedClient(new InetSocketAddress(\"127.0.0.1\", 11211)); // 存储数据 Future future = mcc.set(\"key1\", 900, \"This is Value1\"); // 查看存储状态 System.out.println(\"set status:\" + future.get()); // 缓存读取 System.out.println(\"value in cache : \" + mcc.get(\"key1\")); // 新增数据 mcc.add(\"key2\", 900, \"This is Value2\"); // 数据替换 mcc.replace(\"key2\", 900, \"is\"); // 数据后向追加 mcc.append(\"key2\", 900, \" Value2\"); // 数据前向追缴 mcc.prepend(\"key2\", 900, \"This \"); // 删除数据 mcc.delete(\"key1\"); // 关闭连接 mcc.shutdown(); }catch(Exception ex){ System.out.println( ex.getMessage() ); } }} 4.3.2 Redis&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;相比于Memcache，Redis具有更多的功能扩展性，可以满足更复杂的场景，并且支持String、Hash、Set、List和sorted set类型，还支持数据的持久化、虚拟内存等。它可以用作数据库、缓存和消息中间件。redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Redis支持主从同步，数据可以从主服务器向任意数量的从服务器上同步，从服务器可以是关联其他从服务器的主服务器。由于完全实现了发布/订阅机制，使得从数据库在任何地方同步树时，可订阅一个频道并接收主服务器完整的消息发布记录。同步对读取操作的可扩展性和数据冗余很有帮助 发布/订阅机制：是一种消息通信模式,发布者(pub)发送消息到特定的频道( channel)，订阅者(sub)通过观察频道( channe)接收消息。在分布式环境中，Redis分为客户端和服务端，消息的发布和订阅都是客户端行为，服务端提供channel，如果没有订阅消息，客户端会进入订阅监听状态，一旦接收到订阅消息就会进行消息同步。 类似于，有一档天气预报的节目，节目主持人（channel）实时获得气象局（pub）发布的气象信息，并把消息告诉正在观看节目的观众（订阅者），观众会一直盯着节目看直到收到气象预报并更新大脑关于今天的气象信息。 Redis的虚拟内存技术VM提升了数据保存的界限，其实际原理是当数据量已经达到存储边界，会对数据进行冷热隔离，将热数据继续保存在内存中，而冷数据通过压缩手段保存到磁盘上，压缩后的数据仅为原数据的1/10，虽然冷数据的查询效率不及热数据，但考虑到本身查询频率低，并不会影响整体性能。 12345678910111213141516171819202122232425262728293031323334353637public class RedisJava { public static void main(String[] args) { //连接本地的 Redis 服务 Jedis jedis = new Jedis(\"localhost\"); //查看服务是否运行 System.out.println(\"服务正在运行: \"+jedis.ping()); // redis 字符串 jedis.set(\"key1\", \"This is key1\"); System.out.println(jedis.get(\"key1\")); // redis list jedis.lpush(\"list\", \"val1\"); jedis.lpush(\"list\", \"val2\"); jedis.lpush(\"list\", \"val3\"); jedis.llen(\"list\"); // 长度 List&lt;String&gt; list = jedis.lrange(\"list\", 0 ,2); // 排序 SortingParams sortingParams = new SortingParams(); sortingParams.alpha(); sortingParams.limit(0, 3); jedis.sort(list, sortingParams) // keys Set&lt;String&gt; keys = jedis.keys(\"*\"); Iterator&lt;String&gt; it=keys.iterator() ; // 删除 if (jedis.exists(\"key1\")) jedis.del(\"key1\"); // 过期策略 jedis.persist(\"key1\"); jedis.ttl(\"key1\"); }} 4.3.3 Memcache和Redis的区别以及性能比较&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实际上，两者既存在竞争又存在互补，由于实现细节的不同触手会伸向对方触及不到的业务场景。 内存空间：MemCached可以修改最大内存，但终究首先于内存。Redis增加了VM的特性，突破了物理内存的限制，实现冷热分离。 操作：MemCached数据结构单一，仅用来缓存数据，面向对象保存需要用到序列化和反序列化手段；Redis支持更加丰富的数据类型，也可以在服务器端直接对数据进行丰富的操作,这样可以减少网络IO次数和数据体积。 可靠性：MemCache不支持数据持久化，断电或重启后数据消失。Redis支持数据持久化和数据恢复，允许单点故障，但是同时也会付出性能的代价。 应用场景：Memcache动态系统中减轻数据库负载，提升性能，适合多读少写标准缓存场景。 Redis适用于对读写效率要求都很高，数据处理业务复杂和对安全性要求较高的系统。 性能：性能上都很出色，具体到细节，由于Redis只使用单核，而Memcached可以使用多核，所以平均每一个核上Redis在存储小数据时比 Memcached性能更高。而在100k以上的数据中，Memcached性能要高于Redis。 4.4 JPA缓存策略&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;JPA是Java持久层接口，是官方发布的ORM标准，Hibernate是对JPA的全量实现框架支持全自动处理，移植性更好；Mybatis仅部分遵循JPA规则实现半自动处理，灵活性更高。我们再此不展开讨论两者孰优孰劣，仅从缓存层面来看框架级对持久层缓存的支持情况。 4.4.1 Spring-JPA-Data(Hibernate)缓存策略&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Spring-JPA-Data是Spring框架对实现JPA接口的ORM框架的轻量级封装，默认使用Hibernate。Hibernate缓存包括两大类：一级缓存和二级缓存。一级缓存又被称为“Session的缓存”。Session缓存是内置的，不能被卸载，是事务范围的缓存，session级别缓存数据不共享；二级缓存又称为“SessionFactory的缓存”，由于SessionFactory对象的生命周期和应用程序的整个过程对应，因此Hibernate二级缓存是进程范围或者集群范围的缓存，是可以被不同Session所共享的，默认使用EhCache也可显示的替换为Memcache或其他缓存产品。 一级缓存默认开启，仅存在与session周期内，缓存时间短，范围小，效果不明显。 二级缓存默认不开启，需手动配置开启，是热拔插设计，不影响整体性能，可以显著提高效率，同样的将占用更多的内存空间。 4.4.2 Mybatis缓存策略&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mybatis同样采用一二级缓存策略，情况类似与Hibernate的使用。一级缓存称为SqlSession级缓存，与Hibernate的Session缓存一致，二级缓存属于SqlSessionFactory级别，类似于SessionFactory，不同的是，Mybatis二级缓存支持在单一对象映射中使用，比如针对特定的Mapper进行缓存，这就对选择业务场景使用更有帮助。 4.5 缓存击穿、穿透、雪崩、污染 缓存穿透：缓存和数据库中都没有真实数据，此时大量访问该无效数据造成系统压力增大，如果攻击者使用缓存穿透持续攻击，将造成持久层崩溃。 解决方案 对无效数据访问后可在缓存创建值为null的返回，并设定较短的过期时间，可以有效避免攻击。 业务层添加有效性校验，拦截较容易识别的风险。 缓存击穿：当缓存数据过期，此时QPS达到峰值并对该数据进行大规模并发访问，造成数据库瞬间访问量骤增导致奔溃。击穿的特点是少量数据过期，之后对这些数据高并发访问。 解决方案 甄别热点数据，采用合适的过期策略如LRU或LFU。 在高QPS来临前，设置Redis冷热数据隔离，假如冷数据发生高并发访问，也可以保证从缓存冷数据读取。 业务层创建互斥锁，当缓存数据不存在时，可以保证同一类请求只有一个可以访问数据库，其他请求阻塞，访问成功后刷新缓存，使其他请求通过缓存访问。 缓存雪崩：缓存数据大量过期，此时业务查询增大，同样导致数据库压力骤增容易发生奔溃。雪崩特点是大量数据过期，之后被大量访问，区别于缓存击穿。 解决方案 设置合理的缓存过期策略和过期时间，可以自定义一个过期时间范围，并将缓存单数据过期时间以哈希方式分散到不同时间范围。 可以设置热点数据永久不过期。 缓存污染：系统将不常用的数据从内存移到缓存，造成常用数据的失效，降低了缓存的利用率。缓存容量是弥足珍贵的，容量过大反而容易影响查询效率，所以在有效的空间内保证热点数据很重要。 解决策略 设置合理的过期策略，FIFO、LRU、LFU等。 业务层识别，避免大而全的数据添加进缓存中。","link":"/2020/03/10/2 MySQL/MySQL优化系列（五）/"},{"title":"MySQL优化系列（四）","text":"MySQL优化系列（四） 3.6 锁机制和执行引擎3.6.1 锁定义和分类&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在数据连接池提供数据库多线程操作时，资源的并发访问或操作就容易导致各种并发问题，例如脏读、幻读、不可重复读等。按照锁的控制粒度分类：行级锁（包括间隙锁和next-key）、表级锁、页锁； 按照锁的功能分类：共享锁（读锁）、排它锁（写锁）。由于锁的目的是保证在任务执行过程中避免并发问题，所以它通常由Mysql逻辑分层中的引擎层持有，对服务层隔离，同时由引擎层的特性决定了插件式使用方式。 行级锁：锁的持有对象是数据库表中的一行数据，是粒度最小的锁同时并发程度最高。 间隙锁（Gap-Lock）：是特殊的行级锁，物理空间不存在但逻辑上被锁定的行锁，具有行锁的特性。 next-key：是行锁和间隙锁的组合形式。 表级锁：锁的持有对象是数据库的表，粒度最大同时并发程度最低。 页锁：锁的持有对象是数据库中的磁盘管理最小单位——页，粒度和并发度介于行锁和表锁之间。 共享锁：又称为读锁，其他事务可读不可写。 排它锁：又称为写锁，其他事务不可读不可写。 粒度锁的性能比较： 行级锁： 锁的开销大，影响性能。 粒度最小，并发程度最高，锁冲突概率低，会出现死锁。 适合大量的并发更新同时又有并发查询的场景。 表级锁: 锁的开销小，性能影响低。 粒度最大，并发程度低，锁冲突概率大，不会出现死锁。 适合以查询为主，并发数小的场景。 页锁介于行级锁和表锁之间。 3.6.2 并发和事务&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;常见的关系型数据库事务并发问题包括：脏读、幻读、不可重复读。 脏读：当事务1查询某一行数据时，此时事务2进行了修改，那么事务1读取的数据并非当时查询需要返回的数据。 事务1 事务2 SELECT money FROM tb_account WHERE userId=1; UPDATE tb_account SET money = 1000WHERE userId=1;COMMIT; 查询成功（脏读） 不可重复读：当事务1在第一次查询后事务2进行了修改未提交，事务1再次进行查询发现数据与上一次不一致。 事务1 事务2 SELECT money FROM tb_account WHERE userId=1; UPDATE tb_account SET money = 1000WHERE userId=1; SELECT money FROM tb_account WHERE userId=1;(与上一次上旬结果不一致) ROLLBACK； 幻读：当事务1第一次进行范围查询后事务2新增/删除了一条数据，当事务1再次查询时范围总量与上一次不一致。 事务1 事务2 SELECT * FROM tb_account DELETE FROM tb_accountWHERE userId=1; SELECT * FROM tb_account ROLLBACK; 可以发现，幻读和不可重复读的区别在于前者是多数量查询且修改点是新增和删除，后者是单数据查询且修改点是更新操作。结合3.6.1节介绍，脏读可以通过对事务1查询添加行级共享锁从而避免其他事务写操作干扰，或者对事务2添加行级排他锁，使事务1读操作阻塞；不可重复读可以采取对事务2的写操作添加行级排他锁，使事务1的读取阻塞，在完成写操作后开放读取；幻读，通常采用MVCC + next-key方式保护并发执行。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;事务是数据库处理业务逻辑的基本单位，通常由一组SQL组成，执行状态分为成功和失败回滚。事务具有ACID（酸）特性： 原子性(Actomicity)：业务处理的最小单位，全部成功则事务执行成功，否则事务执行失败进行回滚。 一致性(Consistency)：事务操作中，期间的数据要保持一致状态，例如事务A由增删改查组成，当修改其中一条数据后，相关的比如查询操作也应该进行更改。事务执行结束，内部结构如B+Tree也应该是正确的。 隔离性(Isolation)：由于原子性的存在，不同的事务都应该是独立的个体且不能互相影响，这就需要隔离机制进行保护。 持久性(Durability)：事务执行结束后，对数据的更改应该是永久的。 在Mysql的InnoDB引擎中，所有的操作都被当作事务处理，如果存在并发行为就会产生上节所说的情况发生，而如何防止并发问题发生就依赖锁机制和隔离机制。 3.6.3 多版本并发控制&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;多版本并发控制MVCC（Multi-Version Concurrency Control）是数据库级避免并发的实现手段，主要包括：快照读Snapshot Read和当前读Current Read。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;快照读是指读取操作针对某一版本，普通的查询都为快照读，比如SELECT * FROM tb WHERE ?。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当前读是特殊的快照读，是指读取记录的最新版本，为了避免并发问题对读取结果加锁，以排它锁为主，主要使用在增删改场景中，举个例子，UPDATE tb SET name=xxx WHERE id=1，将WHERE=1读取出的结果进行加锁避免其他事务并发干扰，更新之后成功后释放锁同时更新版本。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;针对MVCC中的版本解释，在mysql中每行数据都有两个隐藏列：创建版本号和删除版本号，这是数据库自动添加的，针对不同CRUD操作进行版本号的更新。 SELECT：只能读取的创建版本号≤系统版本号的，删除版本号≥版本号。 INSERT：把当前事务版本号作为创建版本号。 DELETE：把当前事务版本号作为删除版本号。 UPDATE：将当前的事务版本号标记为旧数据的删除版本号，同时创建新的数据把事务版本号标记为创建版本号，事务提交后覆盖旧数据。 3.6.4 隔离机制&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mysql提供四种隔离级别，包括：Read Uncommitted、Read Committed、Repeatable Read、Serializable。隔离机制的存在使事务并发执行过程中保证数据对外的可见性，或者说针对隔离的场景不同（对并发问题的容忍程度）通常需要按业务实际情况选择，隔离级别越低则性能损耗越小。 Read Uncommitted（RU）：在该隔离级别，所有事务都可以看到其他未提交事务的执行结果，很少用于实际，因为性能不比其他级别好多少，允许脏读、不可重复读、幻读。 Read Committed（RC）：该隔离级别支持一个事务只能看见已经提交事务所做的改变，即未提交数据不可见，允许不可重复读和幻读，不允许脏读。 Repeatable Read（RR）：这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行，允许幻读，不允许脏读和不可重复读，InnoDB可以通过MVCC解决幻读问题。 Serializable：这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题，不允许脏读、不可重复读、幻读。 隔离级别 脏读 不可重复读 幻读 Read Uncommitted √ √ √ Read Committed × √ √ Repeatable Read × × √ Serializable × × × 1234567891011121314151617# 查看当前隔离级别mysql&gt; show variables like &apos;%isolation%&apos;;+-----------------------+-----------------+| Variable_name | Value |+-----------------------+-----------------+| transaction_isolation | REPEATABLE-READ || tx_isolation | REPEATABLE-READ |+-----------------------+-----------------+mysql&gt; set global transaction_isolation =&apos;read-committed&apos;;mysql&gt; show variables like &apos;%isolation%&apos;;+-----------------------+----------------+| Variable_name | Value |+-----------------------+----------------+| transaction_isolation | READ-COMMITTED |+-----------------------+----------------+ 3.6.5 MyISAM与InnoDB引擎及其锁和死锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MyISAM和InnoDB是Mysql最典型的两个插件式数据库引擎，两者最大的不同除了在事务支持上不一样（MyISAM不支持事务），以及B+Tree索引结构不同（非聚簇索引和聚簇索引），最主要的就是锁机制不同。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MyISAM在执行SELECT时，会自动给涉及的表加共享锁，在执行UPDATE、INSERT、DELETE前添加表排他锁，加锁过程不需要用户通过LOCK TABLE显示的干预。它支持在一个线程进行共享锁查询时，其他线程可以并发插入数据以减少线程对表的竞争，例如，在一个线程A对表添加共享锁之后执行SELECT查询，此时线程B可以同时将新数据从表的末尾插入，但这需要满足一个条件，就是当表中没有空闲块（由删除造成的一行数据缺失）时，才能触发此并发行为，否则并发插入是被禁止的。 12345678910111213141516# 查询MyISAM并发插入的状态mysql&gt; show variables like &quot;concurrent_insert&quot;;+-------------------+-------+| Variable_name | Value |+-------------------+-------+| concurrent_insert | AUTO |+-------------------+-------+# 查询表锁竞争mysql&gt; show status like &apos;table_lock%&apos;;+-----------------------+-------+| Variable_name | Value |+-----------------------+-------+| Table_locks_immediate | 111 || Table_locks_waited | 5 |+-----------------------+-------+ 可以通过查询表锁竞争来查看当前锁的阻塞情况，当 Table_locks_waited 过大时存在严重的竞争影响系统执行效率。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;InnoDB支持行级共享锁和排它锁，同时内部实现对表添加的意向锁（IS和IX），意向锁是内部实现的不需要用户手动干预，当InnoDB准备对一行数据添加共享锁时需要先获得该表的意向共享锁IS，同理添加排它锁需要获得意向排它锁IX。在执行UPDATE、INSERT、DELETE时会自动添加排它锁，对于SELECT，一般查询不会加锁。 1234567891011121314151617# 对SELECT手动添加共享锁mysql &gt; SELECT * FROM tb_course WHERE id=5 LOCK IN SHARE MODE;# 对SELECT手动添加排它锁mysql &gt; SELECT * FROM tb_course WHERE id=5 FOR UPDATE;# 查看innodb锁竞争情况mysql&gt; show status like &apos;innodb_row_lock%&apos;;+-------------------------------+-------+| Variable_name | Value |+-------------------------------+-------+| Innodb_row_lock_current_waits | 0 || Innodb_row_lock_time | 0 || Innodb_row_lock_time_avg | 0 || Innodb_row_lock_time_max | 0 || Innodb_row_lock_waits | 0 |+-------------------------------+-------+ 手动添加锁的场景一般时为了保证查询的数据在事务执行期内是最新的，排它锁更为严格因为它不运行其他线程添加锁且必须阻塞，而共享锁则有可能存在其他线程也对同一数据添加了共享锁而不能更新。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;死锁更容易在严格的隔离级别上以及InnoDB上发生，当事务试图以不同的顺序锁定资源时，就可能产生死锁，多个事务同时锁定同一个资源时也可能会产生死锁。所以InnoDB本身也有检测死锁的机制，可以检测到死锁的循环依赖并立即返回一个错误，当死锁发生后，只有部分或完全回滚其中一个事务，才能打破死锁，所以InnoDB采取将持有最少行级排他锁的事务进行回滚作为解除死锁的策略，或者设置死锁超时策略。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MyISAM由于在执行DML或DQL时，一次性添加锁，所以不会发生死锁现象，而InnoDB想要规避死锁发生通常建议在单个事务中一次性获得需要的锁避免加锁顺序不一致导致死锁发生，或者当事务中可能既存在共享锁又存在排它锁，那么直接使用排它锁，以一点效率来换取无死锁的发生；如果修改多个表，则先按顺讯依次添加锁；降低隔离级别。 3.7 Mysql主从复制与Binlog&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;主从复制是指数据可以从一个Master节点数据库异步复制到其他服务器Slaver节点，是实现数据库集群的策略，支持横向扩展，提供”一主多从“或”主主复制“，使用主从复制具有以下优势： 实现数据的热备份，提高数据安全性和容灾率。 满足高性能要求，在QPS达到瓶颈时可以通过多个Slavers策略来实现负载均衡。 对于数据采集、建模等内部业务需求可以采取在Slaver进行而不影响生产性能。 数据下发，远程系统创建本地副本而无需建立远程连接访问。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mysql主从复制原理，如上图所示，在开启主从复制功能后，主节点Master会启动一个IO线程，将主服务器发生的改变通过线程写入转储文件bin-log中，从节点Slaver会启用两个线程——IO线程和SQL线程，IO线程负责从Master的binlog中读取数据并写入本地延迟文件Relay Log中，SQL线程从延迟文件中读取数据并写入本地数据库，这样就完成了一个主从复制周期。 Master的IO线程基于数据库改变（DDL和DML）来启动写binlog操作，而Slaver通过定期探查binlog改变状态来启动IO线程读取数据； 确保Master的数据库版本小于等于Slaver数据库版本； 保证Master和Slaver的时间同步。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;更进一步来说，Master向binlog写操作是基于DDL和DML的发生，SELECT除外，也就说是基于事件保存，所以Slaver读取的也是事件信息并在本地通过SQL线程进行回放重演来完成数据库副本的同步，当master发生高吞吐量导致数据量激增超过Slaver线程的处理能力，或者Slaver发生排它锁导致SQL线程同步数据长时间阻塞就会发生相对较高的延迟反应，为了解决这一状况可以采用如下措施： 实现读写分离，按照常规场景的经验DQL的频率远远高于DML（当然也有少量特殊的相反场景），所以将Master设为只写而从库只读，再通过横向扩展从库或者提高从库硬件性能并配合负载均衡，从而保护Master，并将性能均摊。 再应用层面通过在服务层和持久层添加缓存，缓解数据底层压力。 Master配置 1234567891011121314151617# 编辑配置文件my.ini或my.cnf[mysqld]# 保证log-bin权限开放log-bin=/var/mysql/log/master-log-bin//日志文件格式binlog_format=&quot;mixed&quot; # 集群标识server-id=1# 要进行复制的数据库名binlog-do-db=copied_table# 重启服务 12345678# 保证skip_networking关闭状态，否则Slaver无法完成基于网络的通信mysql&gt; show variables like &apos;%skip_networking%&apos;;+-----------------+-------+| Variable_name | Value |+-----------------+-------+| skip_networking | OFF |+-----------------+-------+ Slaver配置 123456789101112131415# 同样修改配置文件my.ini或my.cnf[mysqld]server-id=2# Master IPmaster-host=192.168.XXX.XXX # 用于创建连接的验证信息master-user=user master-password=123456 master-port=3306master-connect-retry=60# 要进行复制的数据库名binlog-do-db=copied_table 1234# 开启Slavermysql&gt; slave start;# 查看状态mysql&gt; show slave status; 建议专门创建一个用于进行主从复制的数据库账号。 Binlog的另一重要作用 binlog除了是主从复制的重要文件，同时它还是数据恢复的重要文件，当数据库由于各种原因导致数据丢失时，通过mysqlbinlog工具从binlog文件中恢复最近的正常状态。 以上介绍的属于Mysql Replication主从同步方案，由于所有的IO线程（Master的IO Thread和Slaver的IO Thread）都是单向执行的，也就是说Slaver假如发生数据库的改变是无法同步到Master的，所以既要求有客观的管理规则来约束又要求在架构上设计严谨，可想而知如果应用在电商平台或者金融平台等对数据一致性和传输安全性有更高要求的地方则并不那么稳妥，PXC主从同步是为满足这一场景而设计，它以牺牲同步效率为代价，提高了数据传输安全性并通过任意节点的数据更高都会对整个集群节点进行广播更新，从而达到数据一致的要求。 3.8 分库分表策略和MyCAT&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;单机使用的关系型数据库，在遇到业务膨胀数据量递增之后，很容易出现性能瓶颈，例如单表或单库数据量达到千万级甚至更高或者磁盘容量超过100G后，IO损耗、内存占用和CPU占用率都会飙升；当业务请求增多会导致数据访问连接数受限长时间阻塞甚至出现锁竞争和死锁的发生。而此时就需要考虑对现有数据库进行拆分，目的为了减少数据库承载的压力，恢复甚至提升数据库性能。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;做数据拆分时从两个维度进行——垂直拆分和水平拆分，而针对业务场景调整拆分的目标包括数据库和表。拆分（Sharding）就是分区分片的意思。 垂直分库，严格来讲不应该算作优化范畴，更确切的应该归为项目架构的改变。随着业务发展，原先设计的关系型数据库架构中的某些子部分迅速膨胀，已经达到了可以单独成库的条件，那么根据业务耦合性，将这类表及附表抽出单独成库并部署在新环境中，达到垂直分库的目的。这类问题一般出现在关系型数据库设计失误或者初创公司为了考虑成本前期内聚式设计，随着业务攀升不得不面临数据分库，而垂直分库本身的思想与业务层面的大系统按照”微服务”思想拆分子系统类似，要求每个子库完成特定范围的数据持久化能力。 水平分库，当垂直分库之后，数据垂直拆分达到了最小原子，数据库中任然存在大量数据，单表性能仍然受限此时需要进行水平分库，参考3.7（主从复制），创建数据库副本形成集群，通过数据库负载均衡将压力均摊，减小单库压力。 垂直分表，配合业务逻辑将表按照字段进行拆分为原子粒度，减小单表内过多的列从而减少量，提高性能，同时达到了解耦的作用。 水平分表，当单表经过垂直拆分后，任然存在大量数据则针对数据行选择进行库内分表或分库分表策略，库内分表只解决单一数据库内表的拆分，对于单机压力的缓解有限；分库分表实际上就是分布式数据库的原理，在集群中相同的数据表按照一定策略保存不同的数据，但这对数据一致性和分布式事务提出了更高的要求。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在进行水平分表时，需要考虑采用怎样的策略来分配数据保存到不同表中，这种策略一般使用特定字段或哈希存储：（1）特定字段是指，可以按照自增整型主键id划分每张表保存的数据量，例如上图所示，每张子表保存id在百万以内的数据，如果超出则继续水平拆分；这样的特定字段根据业务选取，也可按照时间等信息划分。（2）哈希存储是指，按照某一特性的字段求哈希值的方式将数据均匀分布到多个表中，当然需要考虑极端的哈希冲突问题。特定字段可以是一个也可以是一组，这同样需要与业务逻辑相接壤，比如水平拆分5张用户表User，选择userId和userName作为特征字段求哈希值并保存到对应的一张表中，这样就可以保证该用户的多条数据落入同一个库中，减少简单查询的复杂度。 优缺点比较 垂直拆分 优点 以业务逻辑将数据库解耦，业务清晰； 在高并发场景下，可以有效解决IO、数据连接数的性能问题。 缺点 提高了分布式事务的处理难度； 当进行连接操作JOIN时，只能通过代码层进行高层次的聚合，提升了开发难度。 水平拆分 优点 降低了单个数据库的负载能力，保证了系统稳定，提高并发性。 非设计架构层面的解耦，不会带来应用层更大的修改。 缺点 分片的事务处理难度高，数据同步存在延时可能，一致性无法保障 维护难度大，特别是多次改造后。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在垂直拆分和水平拆分中都提到了分布式事务问题，可想而知在单库单表内的事务总是易于控制的，而分布式下需要考虑到节点之间的通信问题，这就导致分布式事务会损耗相对更多的时间，同时导致在共享资源访问时更容易产生并发冲突和死锁问题，并且在数据不断膨胀拆分越来越频繁时会，这种问题会更加严重并不断放大。分布式事务一般采用事务补偿机制，即当事务发生错误通过采用数据对账检查、日志比对、与标准数据对齐等方式进行检查，不同于事务回滚机制，补偿机制属于事后补救措施，会影响数据一致性。一般采用XA协议方式进行分布式事务控制。限于篇幅，只做简单介绍：XA是一个分布式事务协议，包含两个概念：事务管理器（Transaction Manager,TM）和本地资源管理器（Resources Manager, RM）。事务管理器属于协调者，负责各个本地资源的提交和回滚，资源管理器属于参与者，进行实际的执行操作。它通常有二阶段提交和三阶段提交两种，二阶段是指准备阶段和提交阶段： 准备阶段，协调者给每个参与者发送Prepare消息，每个参与者要么直接返回失败，要么在本地执行事务，执行完毕不进行提交并等待，如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。 提交阶段，如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚消息；否则，发送提交消息，参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当前行业内使用的分库分表数据中间件有很多，通常分为两类：Client和Proxy。client方案的的优点在于不用部署，运维成本很低，但是各个服务之间都需要耦合client依赖；proxy方案优点是对个各个服务都是透明的，但是得需要专门去部署运维。目前使用范围最广的是MyCat，它的前身是阿里维护的Cobar，目前已开源并且社区活跃，用户量也很多，属于proxy层方案。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MyCat发展到目前的版本，已经不是一个单纯的MySQL代理了，它的后端可以支持MySQL、SQL Server、Oracle、DB2、PostgreSQL等主流数据库，也支持MongoDB这种新型NoSQL方式的存储，未来还会支持更多类型的存储。而在最终用户看来，无论是那种存储方式，在MyCat里，都是一个传统的数据库表，支持标准的SQL语句进行数据的操作，这样一来，对前端业务系统来说，可以大幅降低开发难度，提升开发速度。 MyCAT的目标是：低成本的将现有的单机数据库和应用平滑迁移到“云”端，解决数据存储和业务规模迅速增长情况下的数据瓶颈问题。从这一点介绍上来看，能满足数据库数据大量存储，提高了查询性能。","link":"/2020/03/03/2 MySQL/MySQL优化系列（四）/"},{"title":"mysql-5.7.x zip版详细配置","text":"MySQL 5.7.x 解压版配置和服务安装 下载5.7.x zip版本MySQL并解压到本地 在文件根目录下新建my.ini文件，并编辑如下内容 1234567891011121314151617181920[mysqld]port = 3306basedir=A:\\dev\\mysql-5.7.23-winx64datadir=A:\\dev\\mysql-5.7.23-winx64\\data#如果不生效，则使用下列表达形式#basedir=A:\\\\dev\\\\mysql-5.7.23-winx64#datadir=A:\\\\dev\\\\mysql-5.7.23-winx64\\\\datamax_connections=200character-set-server=utf8default-storage-engine=INNODBsql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES[mysql]default-character-set=utf8 注意：此时根目录下还不存在data文件，但需要提前配置好datadir 以管理员权限打开cmd，并进入根目录 123c:\\ &gt; cd A:\\dev\\mysql-5.7.23-winx64A:\\dev\\mysql-5.7.23-winx64 &gt; cd bin 先执行remove操作删除可能存在的服务，在安装新服务 123A:\\dev\\mysql-5.7.23-winx64\\bin &gt; mysqld -removeA:\\dev\\mysql-5.7.23-winx64\\bin &gt; mysqld -instal 初始化MySQL服务，并在根目录下创建data目录，并创建初始化用户root 1A:\\dev\\mysql-5.7.23-winx64\\bin &gt; mysqld --initialize-insecure --user=mysql 启动MySQL服务 1A:\\dev\\mysql-5.7.23-winx64\\bin &gt; net start mysql 为root用户创建登录密码 12A:\\dev\\mysql-5.7.23-winx64\\bin &gt; mysqladmin -u root -p password 新密码Enter password: 由于初始化密码为空，所以第二步骤可以直接enter 登录mysql成功！12345678910111213141516A:\\dev\\mysql-5.7.23-winx64\\bin &gt; mysql -u root -p Enter password:密码Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 9Server version: 5.7.23 MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.mysql&gt;show databases; 安装和破解Navicat Premium 12.x 在这里下载64位12.x版本Navicat Premium 在这里下载注册机 正常安装后使用注册机破解 毕竟不是光彩的事情，详情请戳这里","link":"/2018/10/08/2 MySQL/mysql-5-7-x zip版详细配置/"},{"title":"常用算法——分治法","text":"常用算法——分治法 分而治之，治而合之 说明：文中动态插图援引微信公众号：《五分钟学算法》 概念&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分治法（Divide and Conquer, D&amp;C），将一个复杂问题纵向拆分为多个最优结构原子问题，再将原子问题的求解合并，组成复杂问题的最终解。递归是分治法的常用手段，也是经典手段。 使用条件 复杂问题拆分后就容易求解。 拆分后的原子问题具有最优子结构。 原子问题的解可以合并成复杂问题的解。 原子问题独立存在，不含公共子问题。 算法框架 分解：纵向拆分复杂问题为原子问题。 解决：对原子问题进行求解。 合并：将原子问题解合并，组成最终解。 算法复杂度&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一个规模为n的实例可以划分为k个规模为n/k的实例，其中α个实例是需要求解的： O(N) = αT(n/k) + f(n) f(n)与具体的拆分和合并算法有关。 经典算法归并排序（Merge Sort）： 拆分：将一个无序序列递归拆分，最终拆分为长度为1的子序列。 解决：一次将子序列两两返回并进行排序。 合并：自下而上的对子序列进行合并，最终组成完整的排序后序列。 自上而下拆分， 自下而上合并 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class MergeSorted implements IArraySort { @Override public int[] sort(int[] srcArray) { int[] arr = Arrays.copyOf(srcArray, srcArray.length); // 操作副本排序，不影响原数组 if (arr.length &lt; 2) { return arr; } int middle = srcArray.length / 2; int[] leftArr = Arrays.copyOfRange(arr, 0, middle); int[] rightArr = Arrays.copyOfRange(arr, middle, arr.length); return merge(sort(leftArr), sort(rightArr)); } private int[] merge(int[] leftArr, int[] rightArr) { int[] result = new int[leftArr.length + rightArr.length]; int index = 0; while (leftArr.length &gt; 0 &amp;&amp; rightArr.length &gt; 0) { if (leftArr[0] &lt;= rightArr[0]) { result[index] = leftArr[0]; index++; leftArr = Arrays.copyOfRange(leftArr, 1, leftArr.length); } else { result[index] = rightArr[0]; index++; rightArr = Arrays.copyOfRange(rightArr, 1, rightArr.length); } } while (leftArr.length &gt; 0) { result[index] = leftArr[0]; index ++; leftArr = Arrays.copyOfRange(leftArr, 1, leftArr.length); } while (rightArr.length &gt; 0) { result[index] = rightArr[0]; index ++; rightArr = Arrays.copyOfRange(rightArr, 1, rightArr.length); } return result; } public static void main(String[] args) { int[] arr = {3,23,4,13,4,5,63,6,2}; arr = new MergeSorted().sort(arr); System.out.println(arr.length); for (int i : arr) { System.out.print(i + \" \"); } }} 快速排序（Quick Sort） 解决：设置基准点pivot，并定位两端索引位置left和right，一边排序找到比pivot小的放在左边，比pivot大的放在右边。 拆分：一边排序后，以pivot为分割点，将左右两边序列依次执行步骤1。 合并：将原子序列排序后合并成为最终有序序列。 自上而下排序并拆分 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class QuikSort implements IArraySort { @Override public int[] sort(int[] sourceArray) { // 对 arr 进行拷贝，不改变参数内容 int[] arr = Arrays.copyOf(sourceArray, sourceArray.length); quickSort(arr, 0, arr.length - 1); return arr; } private void quickSort(int[] arr, int left, int right) { if (left &gt; right) { return; } int leftIndex = left; int rightIndex = right; int pivot = arr[leftIndex]; // 基准 while (left &lt; right) { while (left &lt; right &amp;&amp; arr[right] &gt;= pivot) { right--; } while (left &lt; right &amp;&amp; arr[left] &lt;= pivot) { left++; } if (left &lt; right) { swap(arr, right, left); } } swap(arr, leftIndex, left); // 此时left==right quickSort(arr, leftIndex, left-1); quickSort(arr,left + 1, rightIndex); } private void swap(int[] arr, int i, int j) { int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; } public static void main(String[] args) { int[] arr = {6,1,2,7,9,3,4,5,10,8}; arr = new QuikSort().sort(arr); System.out.println(arr.length); for (int i : arr) { System.out.print(i + \" \"); } }} 注意：如果基准点pivot设置为左顶端数，那么应该保证先从右侧开始比较，这样可以保证最终left和right停留的相同位置是小于pivot的，所以可以交换，否则，交换的将是大于pivot的值，不满足快排条件。 汉诺塔 A、B、C三根柱子，其中A柱子上面有从小叠到大的n个圆盘，现要求将A柱子上的圆盘移到C柱子上去，期间只有一个原则：一次只能移到一个盘子且大盘子不能在小盘子上面，求移动的步骤和移动的次数 把n-1个盘子由A 移到 B；把第n个盘子由 A移到 C；把n-1个盘子由B 移到 C； 12345678910111213141516171819202122public class Hanoi { private static int step = 1; // 步数 public static void hanoi(int plateNum, String a, String b, String c) { if (plateNum == 1) { move(plateNum, a, c); } else { hanoi(plateNum - 1, a, c, b); move(plateNum, a, c); hanoi(plateNum - 1, b, a, c); } } private static void move(int plateNum, String from, String to) { System.out.printf(\"%d step, %d plate move from %s to %s \\n\", step++, plateNum, from, to); } public static void main(String[] args) { hanoi(3, \"A\", \"B\", \"C\"); }} 12345671 step, 1 plate move from A to C 2 step, 2 plate move from A to B 3 step, 1 plate move from C to B 4 step, 3 plate move from A to C 5 step, 1 plate move from B to A 6 step, 2 plate move from B to C 7 step, 1 plate move from A to C","link":"/2020/04/01/3 算法/常用算法——分治法/"}],"tags":[{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"MySQL优化","slug":"MySQL优化","link":"/tags/MySQL优化/"},{"name":"数据结构","slug":"数据结构","link":"/tags/数据结构/"},{"name":"缓存","slug":"缓存","link":"/tags/缓存/"},{"name":"算法","slug":"算法","link":"/tags/算法/"}],"categories":[]}