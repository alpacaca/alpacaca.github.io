---
title: MySQL优化系列（四）
date: 2020-3-3
tags: [mysql, MySQL优化]
---
{% asset_img image1.jpg MySQL %}



# MySQL优化系列（四）
<!--more-->

### 3.6 锁机制和执行引擎

#### 3.6.1 锁定义和分类

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在数据连接池提供数据库多线程操作时，资源的并发访问或操作就容易导致各种并发问题，例如脏读、幻读、不可重复读等。**按照锁的控制粒度分类：行级锁（包括间隙锁和next-key）、表级锁、页锁； 按照锁的功能分类：共享锁（读锁）、排它锁（写锁）。**由于锁的目的是保证在任务执行过程中避免并发问题，所以它通常由Mysql逻辑分层中的引擎层持有，对服务层隔离，同时由引擎层的特性决定了插件式使用方式。

> 行级锁：锁的持有对象是数据库表中的一行数据，是粒度最小的锁同时并发程度最高。
>
> 间隙锁（Gap-Lock）：是特殊的行级锁，物理空间不存在但逻辑上被锁定的行锁，具有行锁的特性。
>
> next-key：是行锁和间隙锁的组合形式。
>
> 表级锁：锁的持有对象是数据库的表，粒度最大同时并发程度最低。
>
> 页锁：锁的持有对象是数据库中的磁盘管理最小单位——页，粒度和并发度介于行锁和表锁之间。

>共享锁：又称为读锁，其他事务可读不可写。
>
>排它锁：又称为写锁，其他事务不可读不可写。

粒度锁的性能比较：

行级锁：

1. 锁的开销大，影响性能。
2. 粒度最小，并发程度最高，锁冲突概率低，会出现死锁。
3. 适合大量的并发更新同时又有并发查询的场景。

表级锁:

1. 锁的开销小，性能影响低。
2. 粒度最大，并发程度低，锁冲突概率大，不会出现死锁。
3. 适合以查询为主，并发数小的场景。

页锁介于行级锁和表锁之间。



### 3.6.2 并发和事务

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;常见的关系型数据库事务并发问题包括：**脏读、幻读、不可重复读**。

**脏读**：当事务1查询某一行数据时，此时事务2进行了修改，那么事务1读取的数据并非当时查询需要返回的数据。

| 事务1                                              | 事务2                                                        |
| -------------------------------------------------- | ------------------------------------------------------------ |
| SELECT money FROM tb_account<br /> WHERE userId=1; |                                                              |
|                                                    | UPDATE tb_account SET money = 1000<br />WHERE userId=1;<br />COMMIT; |
| 查询成功（脏读）                                   |                                                              |

**不可重复读：**当事务1在第一次查询后事务2进行了修改未提交，事务1再次进行查询发现数据与上一次不一致。

| 事务1                                                        | 事务2                                                   |
| ------------------------------------------------------------ | ------------------------------------------------------- |
| SELECT money FROM tb_account<br /> WHERE userId=1;           |                                                         |
|                                                              | UPDATE tb_account SET money = 1000<br />WHERE userId=1; |
| SELECT money FROM tb_account<br /> WHERE userId=1;<br />(与上一次上旬结果不一致) |                                                         |
|                                                              | ROLLBACK；                                              |

**幻读：**当事务1第一次进行范围查询后事务2新增/删除了一条数据，当事务1再次查询时范围总量与上一次不一致。

| 事务1                    | 事务2                                       |
| ------------------------ | ------------------------------------------- |
| SELECT * FROM tb_account |                                             |
|                          | DELETE FROM tb_account<br />WHERE userId=1; |
| SELECT * FROM tb_account |                                             |
|                          | ROLLBACK;                                   |

可以发现，**幻读**和**不可重复读**的区别在于前者是多数量查询且修改点是新增和删除，后者是单数据查询且修改点是更新操作。结合3.6.1节介绍，脏读可以通过对事务1查询添加行级共享锁从而避免其他事务写操作干扰，或者对事务2添加行级排他锁，使事务1读操作阻塞；不可重复读可以采取对事务2的写操作添加行级排他锁，使事务1的读取阻塞，在完成写操作后开放读取；幻读，通常采用MVCC + next-key方式保护并发执行。



&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**事务**是数据库处理业务逻辑的基本单位，通常由一组SQL组成，执行状态分为成功和失败回滚。事务具有ACID（酸）特性：

**原子性(Actomicity)**：业务处理的最小单位，全部成功则事务执行成功，否则事务执行失败进行回滚。

**一致性(Consistency)**：事务操作中，期间的数据要保持一致状态，例如事务A由增删改查组成，当修改其中一条数据后，相关的比如查询操作也应该进行更改。事务执行结束，内部结构如B+Tree也应该是正确的。

**隔离性(Isolation)**：由于原子性的存在，不同的事务都应该是独立的个体且不能互相影响，这就需要隔离机制进行保护。

**持久性(Durability)**：事务执行结束后，对数据的更改应该是永久的。

在Mysql的InnoDB引擎中，所有的操作都被当作事务处理，如果存在并发行为就会产生上节所说的情况发生，而如何防止并发问题发生就依赖锁机制和隔离机制。



#### 3.6.3 多版本并发控制

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;多版本并发控制MVCC（Multi-Version Concurrency Control）是数据库级避免并发的实现手段，主要包括：**快照读Snapshot Read**和**当前读Current Read**。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**快照读**是指读取操作针对某一版本，普通的查询都为快照读，比如`SELECT * FROM tb WHERE ?`。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**当前读**是特殊的快照读，是指读取记录的最新版本，为了避免并发问题对读取结果加锁，以排它锁为主，主要使用在增删改场景中，举个例子，`UPDATE tb SET name=xxx WHERE id=1`，将WHERE=1读取出的结果进行加锁避免其他事务并发干扰，更新之后成功后释放锁同时更新**版本**。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;针对MVCC中的版本解释，在mysql中每行数据都有两个隐藏列：**创建版本号**和**删除版本号**，这是数据库自动添加的，针对不同CRUD操作进行版本号的更新。

> SELECT：只能读取的创建版本号≤系统版本号的，删除版本号≥版本号。
>
> INSERT：把当前事务版本号作为创建版本号。
>
> DELETE：把当前事务版本号作为删除版本号。
>
> UPDATE：将当前的事务版本号标记为旧数据的删除版本号，同时创建新的数据把事务版本号标记为创建版本号，事务提交后覆盖旧数据。



#### 3.6.4 隔离机制

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mysql提供四种隔离级别，包括：**Read Uncommitted**、**Read Committed**、**Repeatable Read**、**Serializable**。隔离机制的存在使事务并发执行过程中保证数据对外的可见性，或者说针对隔离的场景不同（对并发问题的容忍程度）通常需要按业务实际情况选择，隔离级别越低则性能损耗越小。

**Read Uncommitted**（RU）：在该隔离级别，所有事务都可以看到其他未提交事务的执行结果，很少用于实际，因为性能不比其他级别好多少，**允许脏读、不可重复读、幻读**。

**Read Committed**（RC）：该隔离级别支持一个事务只能看见已经提交事务所做的改变，即未提交数据不可见，**允许不可重复读和幻读，不允许脏读**。

**Repeatable Read**（RR）：这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行，**允许幻读，不允许脏读和不可重复读**，InnoDB可以通过MVCC解决幻读问题。

**Serializable**：这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题，**不允许脏读、不可重复读、幻读**。

| 隔离级别             | 脏读 | 不可重复读 | 幻读 |
| -------------------- | :--: | :--------: | :--: |
| **Read Uncommitted** |  √   |     √      |  √   |
| **Read Committed**   |  ×   |     √      |  √   |
| **Repeatable Read**  |  ×   |     ×      |  √   |
| **Serializable**     |  ×   |     ×      |  ×   |

```mysql
# 查看当前隔离级别
mysql> show variables like '%isolation%';
+-----------------------+-----------------+
| Variable_name         | Value           |
+-----------------------+-----------------+
| transaction_isolation | REPEATABLE-READ |
| tx_isolation          | REPEATABLE-READ |
+-----------------------+-----------------+

mysql> set global transaction_isolation ='read-committed';

mysql> show variables like '%isolation%';
+-----------------------+----------------+
| Variable_name         | Value          |
+-----------------------+----------------+
| transaction_isolation | READ-COMMITTED |
+-----------------------+----------------+
```



#### 3.6.5 MyISAM与InnoDB引擎及其锁和死锁

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MyISAM和InnoDB是Mysql最典型的两个插件式数据库引擎，两者最大的不同除了在事务支持上不一样（MyISAM不支持事务），以及B+Tree索引结构不同（非聚簇索引和聚簇索引），最主要的就是锁机制不同。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MyISAM在执行SELECT时，会自动给涉及的表加共享锁，在执行UPDATE、INSERT、DELETE前添加表排他锁，加锁过程不需要用户通过LOCK TABLE显示的干预。它支持在一个线程进行共享锁查询时，其他线程可以并发插入数据以减少线程对表的竞争，例如，在一个线程A对表添加共享锁之后执行SELECT查询，此时线程B可以同时将新数据从表的末尾插入，但这需要满足一个条件，就是当表中没有空闲块（由删除造成的一行数据缺失）时，才能触发此并发行为，否则并发插入是被禁止的。

```mysql
# 查询MyISAM并发插入的状态
mysql> show variables like "concurrent_insert";
+-------------------+-------+
| Variable_name     | Value |
+-------------------+-------+
| concurrent_insert | AUTO  |
+-------------------+-------+

# 查询表锁竞争
mysql> show status like 'table_lock%';
+-----------------------+-------+
| Variable_name         | Value |
+-----------------------+-------+
| Table_locks_immediate | 111   |
| Table_locks_waited    | 5     |
+-----------------------+-------+
```

可以通过查询表锁竞争来查看当前锁的阻塞情况，当 Table_locks_waited 过大时存在严重的竞争影响系统执行效率。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;InnoDB支持行级共享锁和排它锁，同时内部实现对表添加的意向锁（IS和IX），意向锁是内部实现的不需要用户手动干预，当InnoDB准备对一行数据添加共享锁时需要先获得该表的意向共享锁IS，同理添加排它锁需要获得意向排它锁IX。在执行UPDATE、INSERT、DELETE时会自动添加排它锁，对于SELECT，一般查询不会加锁。

```mysql
# 对SELECT手动添加共享锁
mysql > SELECT * FROM tb_course WHERE id=5 LOCK IN SHARE MODE;

# 对SELECT手动添加排它锁
mysql > SELECT * FROM tb_course WHERE id=5 FOR UPDATE;

# 查看innodb锁竞争情况
mysql> show status like 'innodb_row_lock%';
+-------------------------------+-------+
| Variable_name                 | Value |
+-------------------------------+-------+
| Innodb_row_lock_current_waits | 0     |
| Innodb_row_lock_time          | 0     |
| Innodb_row_lock_time_avg      | 0     |
| Innodb_row_lock_time_max      | 0     |
| Innodb_row_lock_waits         | 0     |
+-------------------------------+-------+
```

手动添加锁的场景一般时为了保证查询的数据在事务执行期内是最新的，排它锁更为严格因为它不运行其他线程添加锁且必须阻塞，而共享锁则有可能存在其他线程也对同一数据添加了共享锁而不能更新。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**死锁**更容易在严格的隔离级别上以及InnoDB上发生，当事务试图以不同的顺序锁定资源时，就可能产生死锁，多个事务同时锁定同一个资源时也可能会产生死锁。所以InnoDB本身也有检测死锁的机制，可以检测到死锁的循环依赖并立即返回一个错误，当死锁发生后，只有部分或完全回滚其中一个事务，才能打破死锁，所以InnoDB采取将持有最少行级排他锁的事务进行回滚作为解除死锁的策略，或者设置死锁超时策略。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MyISAM由于在执行DML或DQL时，一次性添加锁，所以不会发生死锁现象，而InnoDB想要规避死锁发生通常建议在单个事务中一次性获得需要的锁避免加锁顺序不一致导致死锁发生，或者当事务中可能既存在共享锁又存在排它锁，那么直接使用排它锁，以一点效率来换取无死锁的发生；如果修改多个表，则先按顺讯依次添加锁；降低隔离级别。



### 3.7 Mysql主从复制与Binlog

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;主从复制是指数据可以从一个Master节点数据库异步复制到其他服务器Slaver节点，是实现数据库集群的策略，支持横向扩展，提供”一主多从“或”主主复制“，使用主从复制具有以下优势：

1. 实现数据的热备份，提高数据安全性和容灾率。
2. 满足高性能要求，在QPS达到瓶颈时可以通过多个Slavers策略来实现负载均衡。
3. 对于数据采集、建模等内部业务需求可以采取在Slaver进行而不影响生产性能。
4. 数据下发，远程系统创建本地副本而无需建立远程连接访问。

{% asset_img mysql_cluster.jpg mysql_cluster %}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Mysql主从复制原理**，如上图所示，在开启主从复制功能后，主节点Master会启动一个IO线程，将主服务器发生的改变通过线程写入**转储文件bin-log**中，从节点Slaver会启用两个线程——IO线程和SQL线程，IO线程负责从Master的binlog中读取数据并写入本地**延迟文件Relay Log**中，SQL线程从延迟文件中读取数据并写入本地数据库，这样就完成了一个主从复制周期。

1. Master的IO线程基于数据库改变（DDL和DML）来启动写binlog操作，而Slaver通过定期探查binlog改变状态来启动IO线程读取数据；
2. 确保Master的数据库版本小于等于Slaver数据库版本；
3. 保证Master和Slaver的时间同步。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;更进一步来说，Master向binlog写操作是基于DDL和DML的发生，SELECT除外，也就说是基于事件保存，所以Slaver读取的也是事件信息并在本地通过SQL线程进行回放重演来完成数据库副本的同步，当master发生高吞吐量导致数据量激增超过Slaver线程的处理能力，或者Slaver发生排它锁导致SQL线程同步数据长时间阻塞就会发生相对较高的延迟反应，为了解决这一状况可以采用如下措施：

1. 实现读写分离，按照常规场景的经验DQL的频率远远高于DML（当然也有少量特殊的相反场景），所以将Master设为只写而从库只读，再通过横向扩展从库或者提高从库硬件性能并配合负载均衡，从而保护Master，并将性能均摊。
2. 再应用层面通过在服务层和持久层添加缓存，缓解数据底层压力。

**Master配置**

```txt
# 编辑配置文件my.ini或my.cnf

[mysqld]

# 保证log-bin权限开放
log-bin=/var/mysql/log/master-log-bin

//日志文件格式
binlog_format="mixed" 

# 集群标识
server-id=1

# 要进行复制的数据库名
binlog-do-db=copied_table

# 重启服务
```

```mysql
# 保证skip_networking关闭状态，否则Slaver无法完成基于网络的通信

mysql> show variables like '%skip_networking%';
+-----------------+-------+
| Variable_name   | Value |
+-----------------+-------+
| skip_networking | OFF   |
+-----------------+-------+
```

**Slaver配置**

```txt
# 同样修改配置文件my.ini或my.cnf

[mysqld]
server-id=2
# Master IP
master-host=192.168.XXX.XXX  

# 用于创建连接的验证信息
master-user=user      　　
master-password=123456   
master-port=3306
master-connect-retry=60

# 要进行复制的数据库名
binlog-do-db=copied_table
```

```mysql
# 开启Slaver
mysql> slave start;
# 查看状态
mysql> show slave status;
```

建议专门创建一个用于进行主从复制的数据库账号。

**Binlog**的另一重要作用

binlog除了是主从复制的重要文件，同时它还是数据恢复的重要文件，当数据库由于各种原因导致数据丢失时，通过mysqlbinlog工具从binlog文件中恢复最近的正常状态。

以上介绍的属于**Mysql Replication主从同步**方案，由于所有的IO线程（Master的IO Thread和Slaver的IO Thread）都是单向执行的，也就是说Slaver假如发生数据库的改变是无法同步到Master的，所以既要求有客观的管理规则来约束又要求在架构上设计严谨，可想而知如果应用在电商平台或者金融平台等对数据一致性和传输安全性有更高要求的地方则并不那么稳妥，**PXC主从同步**是为满足这一场景而设计，它以牺牲同步效率为代价，提高了数据传输安全性并通过任意节点的数据更高都会对整个集群节点进行广播更新，从而达到数据一致的要求。

{% asset_img cluster.jpg mysql_cluster %}



### 3.8 分库分表策略和MyCAT

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;单机使用的关系型数据库，在遇到业务膨胀数据量递增之后，很容易出现性能瓶颈，例如单表或单库数据量达到千万级甚至更高或者磁盘容量超过100G后，IO损耗、内存占用和CPU占用率都会飙升；当业务请求增多会导致数据访问连接数受限长时间阻塞甚至出现锁竞争和死锁的发生。而此时就需要考虑对现有数据库进行拆分，目的为了减少数据库承载的压力，恢复甚至提升数据库性能。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;做数据拆分时从两个维度进行——垂直拆分和水平拆分，而针对业务场景调整拆分的目标包括数据库和表。拆分（Sharding）就是分区分片的意思。

**垂直分库**，严格来讲不应该算作优化范畴，更确切的应该归为项目架构的改变。随着业务发展，原先设计的关系型数据库架构中的某些子部分迅速膨胀，已经达到了可以单独成库的条件，那么根据业务耦合性，将这类表及附表抽出单独成库并部署在新环境中，达到垂直分库的目的。这类问题一般出现在关系型数据库设计失误或者初创公司为了考虑成本前期内聚式设计，随着业务攀升不得不面临数据分库，而垂直分库本身的思想与业务层面的大系统按照”微服务”思想拆分子系统类似，要求每个子库完成特定范围的数据持久化能力。

{% asset_img 分库分表1.jpg 垂直分库 %}

**水平分库**，当垂直分库之后，数据垂直拆分达到了最小原子，数据库中任然存在大量数据，单表性能仍然受限此时需要进行水平分库，参考3.7（主从复制），创建数据库副本形成集群，通过数据库负载均衡将压力均摊，减小单库压力。

{% asset_img 分库分表2.jpg 水平分库 %}

**垂直分表**，配合业务逻辑将表按照字段进行拆分为原子粒度，减小单表内过多的列从而减少量，提高性能，同时达到了解耦的作用。

{% asset_img 分库分表3.jpg 垂直分表 %}

**水平分表**，当单表经过垂直拆分后，任然存在大量数据则针对数据行选择进行**库内分表或分库分表策略**，库内分表只解决单一数据库内表的拆分，对于单机压力的缓解有限；分库分表实际上就是分布式数据库的原理，在集群中相同的数据表按照一定策略保存不同的数据，但这对数据一致性和分布式事务提出了更高的要求。

{% asset_img 分库分表4.jpg 水平分表 %}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在进行水平分表时，需要考虑采用怎样的策略来分配数据保存到不同表中，这种策略一般**使用特定字段或哈希存储**：（1）特定字段是指，可以按照自增整型主键id划分每张表保存的数据量，例如上图所示，每张子表保存id在百万以内的数据，如果超出则继续水平拆分；这样的特定字段根据业务选取，也可按照时间等信息划分。（2）哈希存储是指，按照某一特性的字段求哈希值的方式将数据均匀分布到多个表中，当然需要考虑极端的哈希冲突问题。特定字段可以是一个也可以是一组，这同样需要与业务逻辑相接壤，比如水平拆分5张用户表User，选择userId和userName作为特征字段求哈希值并保存到对应的一张表中，这样就可以保证该用户的多条数据落入同一个库中，减少简单查询的复杂度。

**优缺点比较**

> 垂直拆分
>
> 优点
>
> 1. 以业务逻辑将数据库解耦，业务清晰；
> 2. 在高并发场景下，可以有效解决IO、数据连接数的性能问题。
>
> 缺点
>
> 1. 提高了分布式事务的处理难度；
> 2. 当进行连接操作JOIN时，只能通过代码层进行高层次的聚合，提升了开发难度。

> 水平拆分
>
> 优点
>
> 1. 降低了单个数据库的负载能力，保证了系统稳定，提高并发性。
> 2. 非设计架构层面的解耦，不会带来应用层更大的修改。
>
> 缺点
>
> 1. 分片的事务处理难度高，数据同步存在延时可能，一致性无法保障
> 2. 维护难度大，特别是多次改造后。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在垂直拆分和水平拆分中都提到了分布式事务问题，可想而知在单库单表内的事务总是易于控制的，而分布式下需要考虑到节点之间的通信问题，这就导致分布式事务会损耗相对更多的时间，同时导致在共享资源访问时更容易产生并发冲突和死锁问题，并且在数据不断膨胀拆分越来越频繁时会，这种问题会更加严重并不断放大。分布式事务一般采用事务补偿机制，即当事务发生错误通过采用数据对账检查、日志比对、与标准数据对齐等方式进行检查，不同于事务回滚机制，补偿机制属于事后补救措施，会影响数据一致性。一般采用**XA协议**方式进行分布式事务控制。限于篇幅，只做简单介绍：XA是一个分布式事务协议，包含两个概念：事务管理器（Transaction Manager,TM）和本地资源管理器（Resources Manager, RM）。事务管理器属于协调者，负责各个本地资源的提交和回滚，资源管理器属于参与者，进行实际的执行操作。它通常有二阶段提交和三阶段提交两种，二阶段是指准备阶段和提交阶段：

1. 准备阶段，协调者给每个参与者发送Prepare消息，每个参与者要么直接返回失败，要么在本地执行事务，执行完毕不进行提交并等待，如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。
2. 提交阶段，如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚消息；否则，发送提交消息，参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。



&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当前行业内使用的分库分表数据中间件有很多，通常分为两类：Client和Proxy。client方案的的优点在于不用部署，运维成本很低，但是各个服务之间都需要耦合client依赖；proxy方案优点是对个各个服务都是透明的，但是得需要专门去部署运维。目前使用范围最广的是MyCat，它的前身是阿里维护的Cobar，目前已开源并且社区活跃，用户量也很多，属于proxy层方案。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MyCat发展到目前的版本，已经不是一个单纯的MySQL代理了，它的后端可以支持MySQL、SQL Server、Oracle、DB2、PostgreSQL等主流数据库，也支持MongoDB这种新型NoSQL方式的存储，未来还会支持更多类型的存储。而在最终用户看来，无论是那种存储方式，在MyCat里，都是一个传统的数据库表，支持标准的SQL语句进行数据的操作，这样一来，对前端业务系统来说，可以大幅降低开发难度，提升开发速度。

MyCAT的目标是：低成本的将现有的单机数据库和应用平滑迁移到“云”端，解决**数据存储**和**业务规模**迅速增长情况下的数据瓶颈问题。从这一点介绍上来看，能满足数据库数据大量存储，提高了查询性能。

