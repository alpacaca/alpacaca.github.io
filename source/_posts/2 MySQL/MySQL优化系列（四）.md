---
title: MySQL优化系列（四）
date: 2020-3-3
tags: [mysql, MySQL优化]
---
{% asset_img image1.jpg MySQL %}



# MySQL优化系列（四）
<!--more-->

### 3.6 锁机制和执行引擎

#### 3.6.1 锁定义和分类

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在数据连接池提供数据库多线程操作时，资源的并发访问或操作就容易导致各种并发问题，例如脏读、幻读、不可重复读等。**按照锁的控制粒度分类：行级锁（包括间隙锁和next-key）、表级锁、页锁； 按照锁的功能分类：共享锁（读锁）、排它锁（写锁）。**由于锁的目的是保证在任务执行过程中避免并发问题，所以它通常由Mysql逻辑分层中的引擎层持有，对服务层隔离，同时由引擎层的特性决定了插件式使用方式。

> 行级锁：锁的持有对象是数据库表中的一行数据，是粒度最小的锁同时并发程度最高。
>
> 间隙锁（Gap-Lock）：是特殊的行级锁，物理空间不存在但逻辑上被锁定的行锁，具有行锁的特性。
>
> next-key：是行锁和间隙锁的组合形式。
>
> 表级锁：锁的持有对象是数据库的表，粒度最大同时并发程度最低。
>
> 页锁：锁的持有对象是数据库中的磁盘管理最小单位——页，粒度和并发度介于行锁和表锁之间。

>共享锁：又称为读锁，其他事务可读不可写。
>
>排它锁：又称为写锁，其他事务不可读不可写。

粒度锁的性能比较：

行级锁：

1. 锁的开销大，影响性能。
2. 粒度最小，并发程度最高，锁冲突概率低，会出现死锁。
3. 适合大量的并发更新同时又有并发查询的场景。

表级锁:

1. 锁的开销小，性能影响低。
2. 粒度最大，并发程度低，锁冲突概率大，不会出现死锁。
3. 适合以查询为主，并发数小的场景。

页锁介于行级锁和表锁之间。



### 3.6.2 并发和事务

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;常见的关系型数据库事务并发问题包括：**脏读、幻读、不可重复读**。

**脏读**：当事务1查询某一行数据时，此时事务2进行了修改，那么事务1读取的数据并非当时查询需要返回的数据。

| 事务1                                              | 事务2                                                        |
| -------------------------------------------------- | ------------------------------------------------------------ |
| SELECT money FROM tb_account<br /> WHERE userId=1; |                                                              |
|                                                    | UPDATE tb_account SET money = 1000<br />WHERE userId=1;<br />COMMIT; |
| 查询成功（脏读）                                   |                                                              |

**不可重复读：**当事务1在第一次查询后事务2进行了修改未提交，事务1再次进行查询发现数据与上一次不一致。

| 事务1                                                        | 事务2                                                   |
| ------------------------------------------------------------ | ------------------------------------------------------- |
| SELECT money FROM tb_account<br /> WHERE userId=1;           |                                                         |
|                                                              | UPDATE tb_account SET money = 1000<br />WHERE userId=1; |
| SELECT money FROM tb_account<br /> WHERE userId=1;<br />(与上一次上旬结果不一致) |                                                         |
|                                                              | ROLLBACK；                                              |

**幻读：**当事务1第一次进行范围查询后事务2新增/删除了一条数据，当事务1再次查询时范围总量与上一次不一致。

| 事务1                    | 事务2                                       |
| ------------------------ | ------------------------------------------- |
| SELECT * FROM tb_account |                                             |
|                          | DELETE FROM tb_account<br />WHERE userId=1; |
| SELECT * FROM tb_account |                                             |
|                          | ROLLBACK;                                   |

可以发现，**幻读**和**不可重复读**的区别在于前者是多数量查询且修改点是新增和删除，后者是单数据查询且修改点是更新操作。结合3.6.1节介绍，脏读可以通过对事务1查询添加行级共享锁从而避免其他事务写操作干扰，或者对事务2添加行级排他锁，使事务1读操作阻塞；不可重复读可以采取对事务2的写操作添加行级排他锁，使事务1的读取阻塞，在完成写操作后开放读取；幻读，通常采用MVCC + next-key方式保护并发执行。



&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**事务**是数据库处理业务逻辑的基本单位，通常由一组SQL组成，执行状态分为成功和失败回滚。事务具有ACID（酸）特性：

**原子性(Actomicity)**：业务处理的最小单位，全部成功则事务执行成功，否则事务执行失败进行回滚。

**一致性(Consistency)**：事务操作中，期间的数据要保持一致状态，例如事务A由增删改查组成，当修改其中一条数据后，相关的比如查询操作也应该进行更改。事务执行结束，内部结构如B+Tree也应该是正确的。

**隔离性(Isolation)**：由于原子性的存在，不同的事务都应该是独立的个体且不能互相影响，这就需要隔离机制进行保护。

**持久性(Durability)**：事务执行结束后，对数据的更改应该是永久的。

在Mysql的InnoDB引擎中，所有的操作都被当作事务处理，如果存在并发行为就会产生上节所说的情况发生，而如何防止并发问题发生就依赖锁机制和隔离机制。



#### 3.6.3 隔离机制

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mysql提供四种隔离级别，包括：**Read Uncommitted**、**Read Committed**、**Repeatable Read**、**Serializable**。隔离机制的存在使事务并发执行过程中保证数据对外的可见性，或者说针对隔离的场景不同（对并发问题的容忍程度）通常需要按业务实际情况选择，隔离级别越低则性能损耗越小。

**Read Uncommitted**（RU）：在该隔离级别，所有事务都可以看到其他未提交事务的执行结果，很少用于实际，因为性能不比其他级别好多少，**允许脏读、不可重复读、幻读**。

**Read Committed**（RC）：该隔离级别支持一个事务只能看见已经提交事务所做的改变，即未提交数据不可见，**允许不可重复读和幻读，不允许脏读**。

**Repeatable Read**（RR）：这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行，**允许幻读，不允许脏读和不可重复读**，InnoDB可以通过MVCC解决幻读问题。

**Serializable**：这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题，**不允许脏读、不可重复读、幻读**。

| 隔离级别             | 脏读 | 不可重复读 | 幻读 |
| -------------------- | :--: | :--------: | :--: |
| **Read Uncommitted** |  √   |     √      |  √   |
| **Read Committed**   |  ×   |     √      |  √   |
| **Repeatable Read**  |  ×   |     ×      |  √   |
| **Serializable**     |  ×   |     ×      |  ×   |

```mysql
# 查看当前隔离级别
mysql> show variables like '%isolation%';
+-----------------------+-----------------+
| Variable_name         | Value           |
+-----------------------+-----------------+
| transaction_isolation | REPEATABLE-READ |
| tx_isolation          | REPEATABLE-READ |
+-----------------------+-----------------+

mysql> set global transaction_isolation ='read-committed';

mysql> show variables like '%isolation%';
+-----------------------+----------------+
| Variable_name         | Value          |
+-----------------------+----------------+
| transaction_isolation | READ-COMMITTED |
+-----------------------+----------------+
```



#### 3.6.4 MyISAM与InnoDB引擎及其锁和死锁

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MyISAM和InnoDB是Mysql最典型的两个插件式数据库引擎，两者最大的不同除了在事务支持上不一样（MyISAM不支持事务），以及B+Tree索引结构不同（非聚簇索引和聚簇索引），最主要的就是锁机制不同。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MyISAM在执行SELECT时，会自动给涉及的表加共享锁，在执行UPDATE、INSERT、DELETE前添加表排他锁，加锁过程不需要用户通过LOCK TABLE显示的干预。它支持在一个线程进行共享锁查询时，其他线程可以并发插入数据以减少线程对表的竞争，例如，在一个线程A对表添加共享锁之后执行SELECT查询，此时线程B可以同时将新数据从表的末尾插入，但这需要满足一个条件，就是当表中没有空闲块（由删除造成的一行数据缺失）时，才能触发此并发行为，否则并发插入是被禁止的。

```mysql
# 查询MyISAM并发插入的状态
mysql> show variables like "concurrent_insert";
+-------------------+-------+
| Variable_name     | Value |
+-------------------+-------+
| concurrent_insert | AUTO  |
+-------------------+-------+

# 查询表锁竞争
mysql> show status like 'table_lock%';
+-----------------------+-------+
| Variable_name         | Value |
+-----------------------+-------+
| Table_locks_immediate | 111   |
| Table_locks_waited    | 5     |
+-----------------------+-------+
```

可以通过查询表锁竞争来查看当前锁的阻塞情况，当 Table_locks_waited 过大时存在严重的竞争影响系统执行效率。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;InnoDB支持行级共享锁和排它锁，同时内部实现对表添加的意向锁（IS和IX），意向锁是内部实现的不需要用户手动干预，当InnoDB准备对一行数据添加共享锁时需要先获得该表的意向共享锁IS，同理添加排它锁需要获得意向排它锁IX。在执行UPDATE、INSERT、DELETE时会自动添加排它锁，对于SELECT，一般查询不会加锁。

```mysql
# 对SELECT手动添加共享锁
mysql > SELECT * FROM tb_course WHERE id=5 LOCK IN SHARE MODE;

# 对SELECT手动添加排它锁
mysql > SELECT * FROM tb_course WHERE id=5 FOR UPDATE;

# 查看innodb锁竞争情况
mysql> show status like 'innodb_row_lock%';
+-------------------------------+-------+
| Variable_name                 | Value |
+-------------------------------+-------+
| Innodb_row_lock_current_waits | 0     |
| Innodb_row_lock_time          | 0     |
| Innodb_row_lock_time_avg      | 0     |
| Innodb_row_lock_time_max      | 0     |
| Innodb_row_lock_waits         | 0     |
+-------------------------------+-------+
```

手动添加锁的场景一般时为了保证查询的数据在事务执行期内是最新的，排它锁更为严格因为它不运行其他线程添加锁且必须阻塞，而共享锁则有可能存在其他线程也对同一数据添加了共享锁而不能更新。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**死锁**更容易在严格的隔离级别上以及InnoDB上发生，当事务试图以不同的顺序锁定资源时，就可能产生死锁，多个事务同时锁定同一个资源时也可能会产生死锁。所以InnoDB本身也有检测死锁的机制，可以检测到死锁的循环依赖并立即返回一个错误，当死锁发生后，只有部分或完全回滚其中一个事务，才能打破死锁，所以InnoDB采取将持有最少行级排他锁的事务进行回滚作为解除死锁的策略，或者设置死锁超时策略。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MyISAM由于在执行DML或DQL时，一次性添加锁，所以不会发生死锁现象，而InnoDB想要规避死锁发生通常建议在单个事务中一次性获得需要的锁避免加锁顺序不一致导致死锁发生，或者当事务中可能既存在共享锁又存在排它锁，那么直接使用排它锁，以一点效率来换取无死锁的发生；如果修改多个表，则先按顺讯依次添加锁；降低隔离级别。



### 3.7 Mysql主从复制与Binlog

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;主从复制是指数据可以从一个Master节点数据库异步复制到其他服务器Slaver节点，是实现数据库集群的策略，支持横向扩展，提供”一主多从“或”主主复制“，使用主从复制具有以下优势：

1. 实现数据的热备份，提高数据安全性和容灾率。
2. 满足高性能要求，在QPS达到瓶颈时可以通过多个Slavers策略来实现负载均衡。
3. 对于数据采集、建模等内部业务需求可以采取在Slaver进行而不影响生产性能。
4. 数据下发，远程系统创建本地副本而无需建立远程连接访问。

{% asset_img mysql_cluster.jpg mysql_cluster %}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Mysql主从复制原理**，如上图所示，在开启主从复制功能后，主节点Master会启动一个IO线程，将主服务器发生的改变通过线程写入**转储文件bin-log**中，从节点Slaver会启用两个线程——IO线程和SQL线程，IO线程负责从Master的binlog中读取数据并写入本地**延迟文件Relay Log**中，SQL线程从延迟文件中读取数据并写入本地数据库，这样就完成了一个主从复制周期。

1. Master的IO线程基于数据库改变（DDL和DML）来启动写binlog操作，而Slaver通过定期探查binlog改变状态来启动IO线程读取数据；
2. 确保Master的数据库版本小于等于Slaver数据库版本；
3. 保证Master和Slaver的时间同步。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;更进一步来说，Master向binlog写操作是基于DDL和DML的发生，SELECT除外，也就说是基于事件保存，所以Slaver读取的也是事件信息并在本地通过SQL线程进行回放重演来完成数据库副本的同步，当master发生高吞吐量导致数据量激增超过Slaver线程的处理能力，或者Slaver发生排它锁导致SQL线程同步数据长时间阻塞就会发生相对较高的延迟反应，为了解决这一状况可以采用如下措施：

1. 实现读写分离，按照常规场景的经验DQL的频率远远高于DML（当然也有少量特殊的相反场景），所以将Master设为只写而从库只读，再通过横向扩展从库或者提高从库硬件性能并配合负载均衡，从而保护Master，并将性能均摊。
2. 再应用层面通过在服务层和持久层添加缓存，缓解数据底层压力。

**Master配置**

```txt
# 编辑配置文件my.ini或my.cnf

[mysqld]

# 保证log-bin权限开放
log-bin=/var/mysql/log/master-log-bin

//日志文件格式
binlog_format="mixed" 

# 集群标识
server-id=1

# 要进行复制的数据库名
binlog-do-db=copied_table

# 重启服务
```

```mysql
# 保证skip_networking关闭状态，否则Slaver无法完成基于网络的通信

mysql> show variables like '%skip_networking%';
+-----------------+-------+
| Variable_name   | Value |
+-----------------+-------+
| skip_networking | OFF   |
+-----------------+-------+
```

**Slaver配置**

```txt
# 同样修改配置文件my.ini或my.cnf

[mysqld]
server-id=2
# Master IP
master-host=192.168.XXX.XXX  

# 用于创建连接的验证信息
master-user=user      　　
master-password=123456   
master-port=3306
master-connect-retry=60

# 要进行复制的数据库名
binlog-do-db=copied_table
```

```mysql
# 开启Slaver
mysql> slave start;
# 查看状态
mysql> show slave status;
```

建议专门创建一个用于进行主从复制的数据库账号。

**Binlog**的另一重要作用

binlog除了是主从复制的重要文件，同时它还是数据恢复的重要文件，当数据库由于各种原因导致数据丢失时，通过mysqlbinlog工具从binlog文件中恢复最近的正常状态。

以上介绍的属于**Mysql Replication主从同步**方案，由于所有的IO线程（Master的IO Thread和Slaver的IO Thread）都是单向执行的，也就是说Slaver假如发生数据库的改变是无法同步到Master的，所以既要求有客观的管理规则来约束又要求在架构上设计严谨，可想而知如果应用在电商平台或者金融平台等对数据一致性和传输安全性有更高要求的地方则并不那么稳妥，**PXC主从同步**是为满足这一场景而设计，它以牺牲同步效率为代价，提高了数据传输安全性并通过任意节点的数据更高都会对整个集群节点进行广播更新，从而达到数据一致的要求。

{% asset_img cluster.jpg mysql_cluster %}



### 3.8 并发控制

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在一般程序的并发控制过程中，都存在两种策略，分别是：悲观锁和乐观锁。在 Mysql 多事务并发过程中悲观锁策略称为 **”LBCC"**，乐观锁策略称为 **”MVCC“**（实际上，MVCC与乐观锁不同，但从非加锁策略上是一致的）。

#### 3.8.1 LBCC

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LBCC （Lock Based Concurrency Control），是一种基于排它锁的并发策略。当多个事务对统一数据发生并发行为时，如果一个事务首先获得数据执行权，当他执行查询操作，那么会对数据加持共享所（写锁），查询对其他数据可见，而修改使用的排它锁需要被阻塞等待；当他执行修改操作（增删改）时，对数据加持排它锁，其他事务的查询和修改必须被阻塞，等待竞争锁。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在任何时候，悲观锁策略的效率都是很低的，特别对于数据库系统的高可用性影响很大，所以为了提高并发效率 Mysql 采用 MVCC策略。

#### 3.8.2 MVCC

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MVCC（Multi-Version Concurrency Control）又称为多版本并发控制，MVCC 的核心是通过 **版本链快照** 和 一致性对象 **ReadView** 技术来完成，它也是目前主流数据库处理并发的首选方案。在具体的介绍 MVCC 技术前先对相关技术进行介绍。

##### 3.8.2.1 redo日志和undo日志

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Redo日志是**物理层面，针对”页（page）“修改**而创建的日志，它记录了事务执行过程中的写动作，虽然功能上与 Binlog 日志相似，但在本质上有明显区别：

1. Binlog 不区分数据库引擎，都会创建；Redo 日志仅在 InnoDB 引擎中使用；
2. Binlog 虽然也是磁盘保存的二进制文件，但本质上它属于逻辑层日志（针对行数据的变动）；Redo 属于物理层日志，当 page 发生改变，就会被 redo 记录；
3. 在事务处理时，事务中的变动会持续被 Redo 记录；只有当事务提交后才会被 Binlog 记录。



&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Undo 日志是属于逻辑层日志，针对每一行数据修改后记录，它是实现 MVCC 版本链的核心。

##### 3.8.2.2 隔离级别可见性 和 MVCC使用场景

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当多个事务并发执行时，RU 级别的修改对其他事务始终保持可见性；RC 级别只有当事务被提交后对其他事务才具有可见性；RR 级别，当事务被提交后，其他事务内的同一查询始终保持结果一致；Serializable 级别，由于被数据库强制编排执行顺序，所以事务并发结果受数据库影响。因此发挥 **MVCC 并发处理能力的场景只适合 RC 和 RR**。



##### 3.8.2.3 组织版本链

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在 MVCC 中，数据库表中的每条数据都会额外创建两个隐藏字段：当前事务id，记作 data_tx_id 和 回滚id，记作 data_rollback_id（如果数据库没有主键那么还会额外创建一个字段主键id，记作data_key_id）。**data_tx_id** 用于表示修改当前数据的事务id，**data_rollback_id** 是一个指针，指向当前被修改数据前的旧数据id，如果当前数据是新增数据则该指针为空。

**insert 操作**

新增一条数据后，它的 data_tx_id 为当前插入记录的事务 id，即data_tx_id = 事务id，data_rollback_id为空。

**delete 操作**

删除一条数据时，首先会将这行数据添加 排它锁 ，然后将该数据存入 undo 日志中，当事务提交时删除该数据。

**update操作**

1. 对数据添加排它锁，将该数据存入 undo 日志中（data_tx_id，data_rollback_id不变）。
2. **创建一行该数据的副本并进行更新，副本数据中的 data_tx_id 等于当前事务id，data_rollback_id 指向上一条存入 undo 日志中的数据，这样通过指针就创建了当前数据与历史数据的联系，如果存在多个 update 行为，那么就会形成一条连续的版本链，每条版本链对应的数据称为快照数据**。
3. redo 日志记录，包括 undo 日中的修改。

> delete 操作可以看成是特殊的 update 操作。



##### 3.8.2.4 数据读操作的一致性——ReadView列表

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在解决了 DML 操作后，针对 select 操作就牵扯到 RC 和 RR 事务隔离级别对于数据可见性的问题。回顾一下：RC 不允许脏读、允许不可重复读和幻读，那么就意味着一个事务 A 在处理过程中，对事务 B 数据不可见，当 A 提交之后，对事务 B 可见；RR 不允许脏读和可重复读、允许幻读，那么就意味着当开启事务 B 后，无论事务 A 是否提交，都不会对 B 产生影响，即不可见。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;那么，在已经成型的版本链中，如果决定哪些版本对当前事务可见？为了解决这一问题，引入了ReadView 可读视图列表的概念。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当产生 ReadView 列表时，该列表会收集==当前活跃事务的 id（正在执行的事务）== 进行保存，甄别出这些 id 的最小值记为 **tx_min_id**，同时会从==已创建的事务（包含已提交和未提交的事务）==中甄别出最大的 id，记为**tx_max_id**，也假如 ReadView 列表中。

- 在 RR 隔离级别中，当首次触发 select 查询 （称为 touch first read）时，会创建 ReadView 列表并收集相关事务id，在该事务周期内所有的查询都使用这份 ReadView 保持不变。
- 在 RC 隔离级别中，一个事务周期内的不同 select 查询每次都会触发创建 ReadView 列表并收集当前的事务id信息，也就是说，每次的 select 对应的 ReadView 列表不尽相同。

也就是因为在创建 ReadView 列表时的策略不同，最终在 RC 和 RR 中产生了不同的结果。**每个事务的 id 是由 innodb 分配的，呈现递增态势，用以却别事务开启的先后顺序，因此通过事务 id 的大小就可以判断记录的可见性**，以下将根据具体实例阐述 MVCC 的判断过程。



> RC 隔离级别下的 MVCC 执行过程。



{% asset_img mvcc1.png mysql_cluster %}

1. 假设 `set val = 10`时的事务 id 为 100， ,事务 A 的 id 为 200，事务 B 的 id 为 300 。
2. 当事务 A 开启事务后，第一次 select 时触发创建 ==ReadView1== 列表 [100]，其中当前事务id tx_id = 200，由于tx_id  > 100 表示，100 的事务是已经被执行的事务所以可见，查询结果是10。
3. 当事务 B 执行 `update val = 20` 后会将 `val = 10` 保存到 undo log，作为版本链最新的记录，并提交事务刷新数据。
4. 当事务 A 再次执行 select 时，再一次触发创建 ==ReadView2== 列表为[100, 300]，当前事务id tx_id < 300，表示事务 B 以执行完毕，对 A 可见，所以读取结果为 20。



> RR 隔离级别下的 MVCC 执行过程。

{% asset_img mvcc2.png mysql_cluster %}

1. 假设 `set val = 10`时的事务 id 为 100， ,事务 A 的 id 为 200，事务 B 的 id 为 300 。
2. 当事务 A 开启事务后，第一次 select 时触发创建 ==ReadView3== 列表[100]，当前事务id tx_id > 100，表示100的事务已经执行完毕对 A 可见，所以结果为10。
3. 当事务 B 执行 update 并提交事务后，A 再次执行查询，由于在 RR 隔离级别下 第二次查询依然在事务周期内，所以沿用第一次创建的列表 ==ReadView3== [100]，所以结果仍然是10。



### 3.9 分库分表策略

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;单机使用的关系型数据库，在遇到业务膨胀数据量递增之后，很容易出现性能瓶颈，例如单表或单库数据量达到千万级甚至更高或者磁盘容量超过100G后，IO损耗、内存占用和CPU占用率都会飙升；当业务请求增多会导致数据访问连接数受限长时间阻塞甚至出现锁竞争和死锁的发生。而此时就需要考虑对现有数据库进行拆分，目的为了减少数据库承载的压力，恢复甚至提升数据库性能。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;做数据拆分时从两个维度进行——垂直拆分和水平拆分，而针对业务场景调整拆分的目标包括数据库和表。拆分（Sharding）就是分区分片的意思。

**垂直分库**，严格来讲不应该算作优化范畴，更确切的应该归为项目架构的改变。随着业务发展，原先设计的关系型数据库架构中的某些子部分迅速膨胀，已经达到了可以单独成库的条件，那么根据业务耦合性，将这类表及附表抽出单独成库并部署在新环境中，达到垂直分库的目的。这类问题一般出现在关系型数据库设计失误或者初创公司为了考虑成本前期内聚式设计，随着业务攀升不得不面临数据分库，而垂直分库本身的思想与业务层面的大系统按照”微服务”思想拆分子系统类似，要求每个子库完成特定范围的数据持久化能力。

{% asset_img divid1.png 垂直分库 %}

**水平分库**，当垂直分库之后，数据垂直拆分达到了最小原子，数据库中任然存在大量数据，单表性能仍然受限此时需要进行水平分库，参考3.7（主从复制），创建数据库副本形成集群，通过数据库负载均衡将压力均摊，减小单库压力。

{% asset_img divid2.png 水平分库 %}

**垂直分表**，配合业务逻辑将表按照字段进行拆分为原子粒度，减小单表内过多的列从而减少量，提高性能，同时达到了解耦的作用。

{% asset_img divid3.png 垂直分表 %}

**水平分表**，当单表经过垂直拆分后，任然存在大量数据则针对数据行选择进行**库内分表或分库分表策略**，库内分表只解决单一数据库内表的拆分，对于单机压力的缓解有限；分库分表实际上就是分布式数据库的原理，在集群中相同的数据表按照一定策略保存不同的数据，但这对数据一致性和分布式事务提出了更高的要求。

{% asset_img divid4.png 水平分表 %}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在进行水平分表时，需要考虑采用怎样的策略来分配数据保存到不同表中，这种策略一般**使用特定字段或哈希存储**：（1）特定字段是指，可以按照自增整型主键id划分每张表保存的数据量，例如上图所示，每张子表保存id在百万以内的数据，如果超出则继续水平拆分；这样的特定字段根据业务选取，也可按照时间等信息划分。（2）哈希存储是指，按照某一特性的字段求哈希值的方式将数据均匀分布到多个表中，当然需要考虑极端的哈希冲突问题。特定字段可以是一个也可以是一组，这同样需要与业务逻辑相接壤，比如水平拆分5张用户表User，选择userId和userName作为特征字段求哈希值并保存到对应的一张表中，这样就可以保证该用户的多条数据落入同一个库中，减少简单查询的复杂度。

**优缺点比较**

> 垂直拆分
>
> 优点
>
> 1. 以业务逻辑将数据库解耦，业务清晰；
> 2. 在高并发场景下，可以有效解决IO、数据连接数的性能问题。
>
> 缺点
>
> 1. 提高了分布式事务的处理难度；
> 2. 当进行连接操作JOIN时，只能通过代码层进行高层次的聚合，提升了开发难度。

> 水平拆分
>
> 优点
>
> 1. 降低了单个数据库的负载能力，保证了系统稳定，提高并发性。
> 2. 非设计架构层面的解耦，不会带来应用层更大的修改。
>
> 缺点
>
> 1. 分片的事务处理难度高，数据同步存在延时可能，一致性无法保障
> 2. 维护难度大，特别是多次改造后。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在垂直拆分和水平拆分中都提到了分布式事务问题，可想而知在单库单表内的事务总是易于控制的，而分布式下需要考虑到节点之间的通信问题，这就导致分布式事务会损耗相对更多的时间，同时导致在共享资源访问时更容易产生并发冲突和死锁问题，并且在数据不断膨胀拆分越来越频繁时会，这种问题会更加严重并不断放大。分布式事务一般采用事务补偿机制，即当事务发生错误通过采用数据对账检查、日志比对、与标准数据对齐等方式进行检查，不同于事务回滚机制，补偿机制属于事后补救措施，会影响数据一致性。一般采用**XA协议**方式进行分布式事务控制。限于篇幅，只做简单介绍：XA是一个分布式事务协议，包含两个概念：事务管理器（Transaction Manager,TM）和本地资源管理器（Resources Manager, RM）。事务管理器属于协调者，负责各个本地资源的提交和回滚，资源管理器属于参与者，进行实际的执行操作。它通常有二阶段提交和三阶段提交两种，二阶段是指准备阶段和提交阶段：

1. 准备阶段，协调者给每个参与者发送Prepare消息，每个参与者要么直接返回失败，要么在本地执行事务，执行完毕不进行提交并等待，如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。
2. 提交阶段，如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚消息；否则，发送提交消息，参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。



&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当前行业内使用的分库分表数据中间件有很多，通常分为两类：Client 和 Proxy。Client 方案的的优点在于不用部署，运维成本很低，但是各个服务之间都需要耦合 Client 依赖；Proxy 方案优点是对个各个服务都是透明的，但是得需要专门去部署运维。目前使用范围最广的是 MyCat，它的前身是阿里维护的 Cobar，目前已开源并且社区活跃，用户量也很多，属于 Proxy 层方案。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MyCat发展到目前的版本，已经不是一个单纯的MySQL代理了，它的后端可以支持MySQL、SQL Server、Oracle、DB2、PostgreSQL等主流数据库，也支持MongoDB这种新型NoSQL方式的存储，未来还会支持更多类型的存储。而在最终用户看来，无论是那种存储方式，在MyCat里，都是一个传统的数据库表，支持标准的SQL语句进行数据的操作，这样一来，对前端业务系统来说，可以大幅降低开发难度，提升开发速度。

MyCAT的目标是：低成本的将现有的单机数据库和应用平滑迁移到“云”端，解决**数据存储**和**业务规模**迅速增长情况下的数据瓶颈问题。从这一点介绍上来看，能满足数据库数据大量存储，提高了查询性能。



### 3.10 分布式事务控制

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分布式事务是分布式系统，特别是微服务架构中的痛点和难点，通常一个分布式事务中会设计到对多个数据源或业务系统的操作，并满足 ACID 原则。

#### 3.10.1 CAP 理论和 BASE 理论

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**CAP** 理论是分布式系统的基础理论之一，它是指在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容忍性（Partition tolerance）三者不可能同时满足，最多满足其中的两点。

- 一致性：在同一时刻，分布式中的各节点数据应该保证一致。
- 可用性：系统提供提供的服务应该一致保持可用，即使部分节点出现故障，系统整体也能正确相应客户端请求。
- 分区容忍性：系统在遭遇分区故障时，扔可以对客户端的请求做到一致性和可用性。

{% asset_img 特性.png 分布式事务 %}

> 优点：
>
> 原理简单，容易理解和实现。
>
> 
>
> 缺点：
>
> 单点风险，事务管理器执行过程中故障；
>
> 阻塞问题，事务执行过程中所有节点都处于阻塞状态；
>
> 脑裂问题，第二阶段执行过程中，由于某些故障，只有部分节点提交事务，出现出具不一致现象。



**3PC**

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于 2PC 的缺点，3PC（三阶段提交） 进行了改进：在管理器和所有节点间引入超时机制；在 2PC 的阶段前引入准备阶段，分为 **CanCommit、PreCommit、DoCommit**。

==第一阶段==：

1. 事务管理器向所有节点**发出 CanCommit 指令**，询问是否可以提交事务并等待回复；
2. 如果节点认为没有问题反馈 yes，相反地如果被阻塞则反馈 no。

==第二阶段==：

3. 如果第一阶段反馈结果全部是 yes，则再次**发出 PreCommit 指令**并等待回应；各节点执行事务（不提交）并反馈；
4. 如果第一阶段反馈结果存在 no 或者有节点超时，则向所有节点**发出 abort 指令**，各节点中断本次事务。

==第三阶段==：

5. 如果第二阶段反馈结果全部是 yes ，最后**发出 DoCommit 指令**并等待回应，所有节点提交事务并反馈，最终结束本次任务；
6. 如果第二阶段反馈有 no 或者超时，则向所有节点**发出中断指令**，所有节点利用undo log 回滚并反馈，结束本次任务。

> 优点：
>
> 所有节点使用超时机制更加健壮；
>
> 增加CanCommit阶段，尽早发现阻塞节点。
>
> 
>
> 缺点：
>
> 脑裂问题依然存在（数据不一致）。



#### 3.10.3 TCC

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TCC 采用服务化的事务补偿机制，需要事务编码实现<font color=red>T</font>ry、<font color=red>C</font>onfirm、<font color=red>C</font>ancel 三个接口方法，相比于 XA 的数据持久层设计，TCC 提高到业务逻辑层设计。

1. Try 主要对业务系统进行检查，并预留出可供事务执行的资源，只有所有参与者 Try 成功，才算该阶段成功。
2. Confirm 主要对业务系统做确认提交，在 Try 成功的基础上做最终执行。
3. Cancel 在 2 执行失败后，需要实现回滚的逻辑，以及释放 Try 时预留的资源。





> 优点：
>
> 与2PC逻辑类似，容易理解，由业务层实现，促使事务实现粒度更可控。
>
> 
>
> 缺点：
>
> 由于需要编码提供接口实现，具有侵入性。



#### 3.10.4 消息队列





#### 3.10.5 Saga